{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSvjwmu3vPMR"
      },
      "source": [
        "# Final Project - Reinforcements Learning \n",
        "Hello dear students,<br> this is the template notebook. Please click on the \"File\" tab and then on \"Save a copy into drive\".\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "### Name and ID:\n",
        "Student 1: Aviv Slobodkin 307847962\n",
        "<br>\n",
        "Student 2: Shir Ashury Tahan 203284849\n",
        "<br><br>\n",
        "<img src=\"https://play-lh.googleusercontent.com/e_oKlKPISbgdzut1H9opevS7-LTB8-8lsmpCdMkhlnqFenZhpjxbLmx7l158-xQQCIY\">\n",
        "\n",
        "### https://github.com/mpSchrader/gym-sokoban"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !sudo apt-get update\n",
        "# !sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "# !pip install 'imageio==2.4.0'\n",
        "# !pip install gym\n",
        "# !pip install pygame\n",
        "# !apt-get install python-opengl -y\n",
        "# !apt install xvfb -y\n",
        "# !pip install pyvirtualdisplay\n",
        "# !pip install piglet\n",
        "# !pip install gym\n",
        "# !apt-get install python-opengl -y\n",
        "# !apt install xvfb -y\n",
        "# !pip install gym_sokoban\n",
        "# !git clone https://github.com/avivg7/sokoban-so.git\n",
        "# !unzip /content/sokoban-so/Compress.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "1cNdWkV49OqN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.utils import seeding\n",
        "from gym import error, spaces, utils\n",
        "gymlogger.set_level(40) # error only\n",
        "from soko_pap import *\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "import pygame\n",
        "import pyvirtualdisplay\n",
        "import imageio\n",
        "import IPython\n",
        "import time\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.optimizers import schedules\n",
        "from scipy.special import softmax\n",
        "from collections import deque\n",
        "import pdb\n",
        "import pickle\n",
        "\n",
        "TILE_SIZE=16\n",
        "IS_TINY_RGB=False\n",
        "ONLY_PERMITTED_ACTIONS = False\n",
        "IS_REWARD_SHAPING = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "# Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyJXH2IO72xF"
      },
      "source": [
        "Function - given an environment it will print us the details about observation, actions, agent's position and boxes locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "1UwaHk7t7eIj"
      },
      "outputs": [],
      "source": [
        "def print_env_det(env):\n",
        "  print(f'Observation space: {env.observation_space}'\n",
        "      f'\\nAction space: {env.action_space}'\n",
        "      f'\\nPlayer position:{env.player_position}'\n",
        "      f'\\nBox mapping: {env.box_mapping}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "C8uBk37JFz2M"
      },
      "outputs": [],
      "source": [
        "def run_video(trained_sokoban, MAX_STEPS_IN_EPISODE=500):\n",
        "  iter = 0\n",
        "  env = trained_sokoban.get_env()\n",
        "  policy = trained_sokoban.get_policy()\n",
        "  state_size = trained_sokoban.state_size\n",
        "\n",
        "  if trained_sokoban.get_isFixed():\n",
        "    random.seed(2)\n",
        "  else:\n",
        "    random.seed()\n",
        "  state = env.reset()\n",
        "\n",
        "  total_rewards = 0\n",
        "  done = False\n",
        "  video_filename = 'imageio.mp4'\n",
        "  with imageio.get_writer(video_filename, fps=3) as video:\n",
        "      video.append_data(env.render(mode='rgb_array'))\n",
        "      while (iter < MAX_STEPS_IN_EPISODE):\n",
        "        if done:\n",
        "          break\n",
        "        if IS_TINY_RGB:\n",
        "          state = env.render(mode='tiny_rgb_array')\n",
        "        state = preprocess_state(state, state_size)\n",
        "        # state = state.reshape(1,state_size[0],state_size[1],3)        \n",
        "        # act_values = policy.actor.predict(state, verbose=0)\n",
        "        # # print(act_values)\n",
        "\n",
        "        # curr_allowed_actions = allowed_actions(env)\n",
        "        # if ONLY_PERMITTED_ACTIONS:\n",
        "        #   act_values[0] = [-np.inf if not i in curr_allowed_actions else elem for i,elem in enumerate(act_values[0])]\n",
        "        # action = np.argmax(act_values[0])\n",
        "\n",
        "        action = policy.act(state)\n",
        "        print_env_det(env)\n",
        "\n",
        "\n",
        "        new_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        print(f\"action taken: {action} ({action_translation(action)})\")\n",
        "\n",
        "        total_rewards += reward\n",
        "        state = new_state\n",
        "        video.append_data(env.render(mode='rgb_array'))\n",
        "        iter = iter + 1\n",
        "\n",
        "  print(\"steps: \" + str(iter))\n",
        "  return embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYGqP1yr7iJA"
      },
      "source": [
        "# General Util Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "9oFFvqLdWmRZ"
      },
      "outputs": [],
      "source": [
        "def action_translation(action_i):\n",
        "  action_dict = {0:\"Push Right\", \n",
        "                 1:\"Push Up\", 2:\"Push Down\", 3:\"Push Left\", 4:\"Push Right\",\n",
        "                 5:\"Move Up\", 6:\"Move Down\", 7:\"Move Left\", 8:\"Move Right\",\n",
        "                 9:\"Pull Up\", 10:\"Pull Down\", 11:\"Pull Left\", 12:\"Pull Right\"}\n",
        "  return action_dict[action_i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "L7xCSSegXzvt"
      },
      "outputs": [],
      "source": [
        "def preprocess_state(state, state_size):\n",
        "  img = Image.fromarray(state)\n",
        "  #crop frame - it's constant during all the games\n",
        "  left = 1 if IS_TINY_RGB else TILE_SIZE\n",
        "  top = 1 if IS_TINY_RGB else TILE_SIZE\n",
        "  right = state.shape[0] - TILE_SIZE\n",
        "  bottom = state.shape[0] - TILE_SIZE\n",
        "  new_img = img.crop((left,top,right,bottom))\n",
        "  #resize to smaller image\n",
        "  resized_img = new_img.resize((state_size[0],state_size[1]))\n",
        "  # resized_img = new_img.resize((5,5)) if IS_TINY_RGB else new_img.resize((32,32))\n",
        "  return np.array(resized_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_box_location(env):\n",
        "    idx = np.argmax(env.room_state == 4)\n",
        "    if env.room_state.flat[idx] == 4:\n",
        "        return np.unravel_index(idx, env.room_state.shape)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reward_shaping(reward, box_location_old, box_location_new, target_location):\n",
        "    distance_old = np.abs(box_location_old[0]-target_location[0]) + np.abs(box_location_old[1]-target_location[1])\n",
        "    distance_new = np.abs(box_location_new[0]-target_location[0]) + np.abs(box_location_new[1]-target_location[1])\n",
        "    reward = reward - distance_new + distance_old\n",
        "    return reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "Bv666U5CBEb0"
      },
      "outputs": [],
      "source": [
        "def allowed_actions(env):\n",
        "  allowed_actions = [\"Push Up\", \"Push Down\", \"Push Left\", \"Push Right\",\n",
        "                     \"Move Up\", \"Move Down\", \"Move Left\", \"Move Right\",\n",
        "                     \"Pull Up\", \"Pull Down\", \"Pull Left\", \"Pull Right\"]\n",
        "\n",
        "  pl_y,pl_x = env.player_position\n",
        "  box_y, box_x = list(env.box_mapping.values())[0]\n",
        "  room_state = env.room_state # indicates locations of walls (0), and non-walls (o.w.)\n",
        "  \n",
        "  # stands by the walls\n",
        "  if pl_y == 6 or room_state[pl_y+1,pl_x] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Down\")]\n",
        "  if pl_y == 0 or room_state[pl_y-1,pl_x] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Up\")]\n",
        "  if pl_x == 6 or room_state[pl_y,pl_x+1] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Right\")]\n",
        "  if pl_x == 0 or room_state[pl_y,pl_x-1] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Left\")]\n",
        "  \n",
        "  # box is by the frame walls and player adjacent\n",
        "  if pl_x == box_x and box_y == pl_y+1 and room_state[box_y+1,box_x] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Down\")]\n",
        "  if pl_x == box_x and box_y == pl_y-1 and room_state[box_y-1,box_x] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Up\")]\n",
        "  if pl_y == box_y and box_x == pl_x+1 and room_state[box_y,box_x+1] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Right\")]\n",
        "  if pl_y == box_y and box_x == pl_x-1 and room_state[box_y,box_x-1] == 0:\n",
        "    allowed_actions = [a for a in allowed_actions if not a.endswith(\"Left\")]\n",
        "\n",
        "  \n",
        "  # can only push if box in front\n",
        "  if pl_x == box_x and box_y == pl_y+1:\n",
        "    allowed_actions = [a for a in allowed_actions if not a in [\"Move Down\", \"Pull Down\"]]\n",
        "  if pl_x == box_x and box_y == pl_y-1:\n",
        "    allowed_actions = [a for a in allowed_actions if not a in [\"Move Up\", \"Pull Up\"]]\n",
        "  if pl_y == box_y and box_x == pl_x+1:\n",
        "    allowed_actions = [a for a in allowed_actions if not a in [\"Move Right\", \"Pull Right\"]]\n",
        "  if pl_y == box_y and box_x == pl_x-1:\n",
        "    allowed_actions = [a for a in allowed_actions if not a in [\"Move Left\", \"Pull Left\"]]\n",
        "\n",
        "  # if stuck (no actions are allowed)\n",
        "  if len(allowed_actions) == 0:\n",
        "    return list(range(13))\n",
        "    \n",
        "  return [action_i for action_i in range(13) if action_translation(action_i) in allowed_actions]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDOSvPAwb4dN"
      },
      "source": [
        "# Actor-Critic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP8u7VmDXqEG"
      },
      "source": [
        "### Actor-Critic class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "bi8fiFFXXj1x"
      },
      "outputs": [],
      "source": [
        "class A2C():\n",
        "    def __init__(self, state_size, action_size, \n",
        "                 critic_lr=0.01, actor_lr=0.01, gamma=0.99, \n",
        "                 epsilon=0.99, epsilon_min=0.1, epsilon_decay=0.98,\n",
        "                 weight_backup_critic=\"sokoban_weight_critic.h5\",\n",
        "                 weight_backup_actor=\"sokoban_weight_actor.h5\"):\n",
        "                 \n",
        "        self.weight_backup_critic      = weight_backup_critic\n",
        "        self.weight_backup_actor       = weight_backup_actor\n",
        "        self.state_size                = state_size\n",
        "        self.action_size               = action_size\n",
        "        self.memory                    = deque(maxlen=2000)\n",
        "        self.critic_lr                 = critic_lr \n",
        "        self.gamma                     = gamma \n",
        "        self.epsilon                   = epsilon\n",
        "        self.epsilon_min               = epsilon_min\n",
        "        self.epsilon_decay             = epsilon_decay \n",
        "        self.actor_lr                  = actor_lr\n",
        "        self.actor_lr_schedule         = schedules.ExponentialDecay(\n",
        "                                          initial_learning_rate=self.actor_lr,\n",
        "                                          decay_steps=10000,\n",
        "                                          decay_rate=0.9)\n",
        "        self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate=self.actor_lr_schedule)\n",
        "\n",
        "        self.critic = self._build_critic()\n",
        "        self.actor  = self._build_actor()\n",
        "\n",
        "        print(\"critic model:\")\n",
        "        print(self.critic.summary()) \n",
        "        print(\"#########################################################\")\n",
        "        print(\"actor model:\")\n",
        "        print(self.actor.summary()) \n",
        "\n",
        "    def _build_critic(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=self.state_size))\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "\n",
        "        lr_schedule = schedules.ExponentialDecay(\n",
        "                                  initial_learning_rate=self.critic_lr,\n",
        "                                  decay_steps=10000,\n",
        "                                  decay_rate=0.9)\n",
        "        model.compile(loss='mse', optimizer=Adam(learning_rate=lr_schedule))\n",
        "\n",
        "        # model.compile(loss='mse', optimizer=Adam(learning_rate=self.critic_lr))\n",
        "\n",
        "        if os.path.isfile(self.weight_backup_critic):\n",
        "            print(f\"Found saved critic weights. Loading model from {self.weight_backup_critic}\")\n",
        "            model.load_weights(self.weight_backup_critic)\n",
        "            self.epsilon = self.epsilon_min\n",
        "        return model\n",
        "\n",
        "    def _build_actor(self): \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=self.state_size))\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='softmax'))\n",
        "\n",
        "        if os.path.isfile(self.weight_backup_actor):\n",
        "            print(f\"Found saved actor weights. Loading model from {self.weight_backup_actor}\")\n",
        "            model.load_weights(self.weight_backup_actor)\n",
        "            self.epsilon = self.epsilon_min\n",
        "        return model\n",
        "\n",
        "    def save_model(self):\n",
        "            self.critic.save(self.weight_backup_critic)\n",
        "            self.actor.save(self.weight_backup_actor)\n",
        "\n",
        "    def act(self, state, curr_env=None):\n",
        "        if curr_env != None:\n",
        "          curr_allowed_actions = allowed_actions(curr_env)\n",
        "        else:\n",
        "          curr_allowed_actions = list(range(self.action_size))\n",
        "\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        state = state.reshape(1,self.state_size[0],self.state_size[1],3)\n",
        "        act_values = self.actor.predict(state, verbose=0)\n",
        "        if ONLY_PERMITTED_ACTIONS:\n",
        "          act_values[0] = [-np.inf if not i in curr_allowed_actions else elem for i,elem in enumerate(act_values[0])]\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "\n",
        "    def fit_critic(self, sample_batch):\n",
        "      targets = []\n",
        "      for state, action, reward, next_state, done in sample_batch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "            next_state = next_state.reshape(1,self.state_size[0],self.state_size[1],3)\n",
        "            action_prime = self.act(next_state)\n",
        "            target = reward + self.gamma * self.critic.predict(next_state, verbose=0)[0][action_prime]\n",
        "            targets.append(target)\n",
        "          else:\n",
        "            targets.append(reward)\n",
        "          state = state.reshape(1,self.state_size[0],self.state_size[1],3)\n",
        "          target_f = self.critic.predict(state, verbose=0)\n",
        "          target_f[0][action] = target\n",
        "          self.critic.fit(state, target_f, epochs=1, verbose=0)\n",
        "      return targets\n",
        "\n",
        "    def fit_actor(self, sample_batch, targets):\n",
        "\n",
        "      batch_states = tf.stack([tpl[0] for tpl in sample_batch])\n",
        "      batch_actions_real = tf.convert_to_tensor([self.act(tpl[0]) for tpl in sample_batch])\n",
        "\n",
        "    \n",
        "      batch_actions_real = tf.one_hot(batch_actions_real, depth=self.action_size)\n",
        "\n",
        "      critic_values = [np.mean(self.critic.predict(tpl[0].reshape(1,self.state_size[0],self.state_size[1],3), verbose=0)[0]) for tpl in sample_batch]\n",
        "\n",
        "      # need to convert to float32 due to tf compatability\n",
        "      critic_values = np.array(critic_values).astype('float32')\n",
        "      targets = np.array(targets).astype('float32')\n",
        "\n",
        "      try:\n",
        "        advantages = tf.convert_to_tensor(targets) -  tf.convert_to_tensor(critic_values)\n",
        "      except:\n",
        "        a = 3\n",
        "      with tf.GradientTape() as tape:\n",
        "        action_probs = self.actor(batch_states, training=True) # Forward pass\n",
        "\n",
        "        # to avoid log-probabilities that are -inf (i.e., prob=0)\n",
        "        action_probs = tf.clip_by_value(action_probs, 1e-20, 1.0)\n",
        "\n",
        "        neg_log_probs = tf.reduce_sum(-tf.math.log(action_probs) * batch_actions_real, axis=1)\n",
        "        actor_loss = tf.reduce_mean(neg_log_probs * advantages)\n",
        "      actor_gradients = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "      self.actor_optimizer.apply_gradients(zip(actor_gradients, self.actor.trainable_variables))\n",
        "\n",
        "      return actor_loss\n",
        "\n",
        "\n",
        "    def replay(self, sample_batch_size, isNewEpisode):\n",
        "        if len(self.memory) < sample_batch_size:\n",
        "            return\n",
        "        sample_batch = random.sample(self.memory, sample_batch_size)\n",
        "        \n",
        "        # fit Critic\n",
        "        targets = self.fit_critic(sample_batch)\n",
        "        \n",
        "        # fit Actor\n",
        "        loss = self.fit_actor(sample_batch, targets)\n",
        "        # if isNewEpisode:\n",
        "        #   print(f\"Actor loss:{loss}\")\n",
        "\n",
        "\n",
        "        if self.epsilon > self.epsilon_min and isNewEpisode:\n",
        "            self.epsilon *= self.epsilon_decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "class A2C_small():\n",
        "    def __init__(self, state_size, action_size, \n",
        "                 critic_lr=0.01, actor_lr=0.01, gamma=0.99, \n",
        "                 epsilon=0.99, epsilon_min=0.1, epsilon_decay=0.98,\n",
        "                 weight_backup_critic=\"sokoban_weight_critic.h5\",\n",
        "                 weight_backup_actor=\"sokoban_weight_actor.h5\"):\n",
        "                 \n",
        "        self.weight_backup_critic      = weight_backup_critic\n",
        "        self.weight_backup_actor       = weight_backup_actor\n",
        "        self.state_size                = state_size\n",
        "        self.action_size               = action_size\n",
        "        self.memory                    = deque(maxlen=2000)\n",
        "        self.critic_lr                 = critic_lr \n",
        "        self.gamma                     = gamma \n",
        "        self.epsilon                   = epsilon\n",
        "        self.epsilon_min               = epsilon_min\n",
        "        self.epsilon_decay             = epsilon_decay \n",
        "        self.actor_lr                  = actor_lr\n",
        "        self.actor_lr_schedule         = schedules.ExponentialDecay(\n",
        "                                          initial_learning_rate=self.actor_lr,\n",
        "                                          decay_steps=10000,\n",
        "                                          decay_rate=0.9)\n",
        "        self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate=self.actor_lr_schedule)\n",
        "\n",
        "        self.critic = self._build_critic()\n",
        "        self.actor  = self._build_actor()\n",
        "\n",
        "        print(\"critic model:\")\n",
        "        print(self.critic.summary()) \n",
        "        print(\"#########################################################\")\n",
        "        print(\"actor model:\")\n",
        "        print(self.actor.summary()) \n",
        "\n",
        "    def _build_critic(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=self.state_size))\n",
        "        # model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        # model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        # model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "\n",
        "        lr_schedule = schedules.ExponentialDecay(\n",
        "                                  initial_learning_rate=self.critic_lr,\n",
        "                                  decay_steps=10000,\n",
        "                                  decay_rate=0.9)\n",
        "        model.compile(loss='mse', optimizer=Adam(learning_rate=lr_schedule))\n",
        "\n",
        "        # model.compile(loss='mse', optimizer=Adam(learning_rate=self.critic_lr))\n",
        "\n",
        "        if os.path.isfile(self.weight_backup_critic):\n",
        "            print(f\"Found saved critic weights. Loading model from {self.weight_backup_critic}\")\n",
        "            model.load_weights(self.weight_backup_critic)\n",
        "            self.epsilon = self.epsilon_min\n",
        "        return model\n",
        "\n",
        "    def _build_actor(self): \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=self.state_size))\n",
        "        # model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        # model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        # model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='softmax'))\n",
        "\n",
        "        if os.path.isfile(self.weight_backup_actor):\n",
        "            print(f\"Found saved actor weights. Loading model from {self.weight_backup_actor}\")\n",
        "            model.load_weights(self.weight_backup_actor)\n",
        "            self.epsilon = self.epsilon_min\n",
        "        return model\n",
        "\n",
        "    def save_model(self):\n",
        "            self.critic.save(self.weight_backup_critic)\n",
        "            self.actor.save(self.weight_backup_actor)\n",
        "\n",
        "    def act(self, state, curr_env=None):\n",
        "        if curr_env != None:\n",
        "          curr_allowed_actions = allowed_actions(curr_env)\n",
        "        else:\n",
        "          curr_allowed_actions = list(range(self.action_size))\n",
        "\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        state = state.reshape(1,self.state_size[0],self.state_size[1],3)\n",
        "        act_values = self.actor.predict(state, verbose=0)\n",
        "        if ONLY_PERMITTED_ACTIONS:\n",
        "          act_values[0] = [-np.inf if not i in curr_allowed_actions else elem for i,elem in enumerate(act_values[0])]\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "\n",
        "    def fit_critic(self, sample_batch):\n",
        "      targets = []\n",
        "      for state, action, reward, next_state, done in sample_batch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "            next_state = next_state.reshape(1,self.state_size[0],self.state_size[1],3)\n",
        "            action_prime = self.act(next_state)\n",
        "            target = reward + self.gamma * self.critic.predict(next_state, verbose=0)[0][action_prime]\n",
        "            targets.append(target)\n",
        "          else:\n",
        "            targets.append(reward)\n",
        "          state = state.reshape(1,self.state_size[0],self.state_size[1],3)\n",
        "          target_f = self.critic.predict(state, verbose=0)\n",
        "          target_f[0][action] = target\n",
        "          self.critic.fit(state, target_f, epochs=1, verbose=0)\n",
        "      return targets\n",
        "\n",
        "    def fit_actor(self, sample_batch, targets):\n",
        "\n",
        "      batch_states = tf.stack([tpl[0] for tpl in sample_batch])\n",
        "      batch_actions_real = tf.convert_to_tensor([self.act(tpl[0]) for tpl in sample_batch])\n",
        "\n",
        "    \n",
        "      batch_actions_real = tf.one_hot(batch_actions_real, depth=self.action_size)\n",
        "\n",
        "      critic_values = [np.mean(self.critic.predict(tpl[0].reshape(1,self.state_size[0],self.state_size[1],3), verbose=0)[0]) for tpl in sample_batch]\n",
        "\n",
        "      # need to convert to float32 due to tf compatability\n",
        "      critic_values = np.array(critic_values).astype('float32')\n",
        "      targets = np.array(targets).astype('float32')\n",
        "\n",
        "      try:\n",
        "        advantages = tf.convert_to_tensor(targets) -  tf.convert_to_tensor(critic_values)\n",
        "      except:\n",
        "        a = 3\n",
        "      with tf.GradientTape() as tape:\n",
        "        action_probs = self.actor(batch_states, training=True) # Forward pass\n",
        "\n",
        "        # to avoid log-probabilities that are -inf (i.e., prob=0)\n",
        "        action_probs = tf.clip_by_value(action_probs, 1e-20, 1.0)\n",
        "\n",
        "        neg_log_probs = tf.reduce_sum(-tf.math.log(action_probs) * batch_actions_real, axis=1)\n",
        "        actor_loss = tf.reduce_mean(neg_log_probs * advantages)\n",
        "      actor_gradients = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "      self.actor_optimizer.apply_gradients(zip(actor_gradients, self.actor.trainable_variables))\n",
        "\n",
        "      return actor_loss\n",
        "\n",
        "\n",
        "    def replay(self, sample_batch_size, isNewEpisode):\n",
        "        if len(self.memory) < sample_batch_size:\n",
        "            return\n",
        "        sample_batch = random.sample(self.memory, sample_batch_size)\n",
        "        \n",
        "        # fit Critic\n",
        "        targets = self.fit_critic(sample_batch)\n",
        "        \n",
        "        # fit Actor\n",
        "        loss = self.fit_actor(sample_batch, targets)\n",
        "        # if isNewEpisode:\n",
        "        #   print(f\"Actor loss:{loss}\")\n",
        "\n",
        "\n",
        "        if self.epsilon > self.epsilon_min and isNewEpisode:\n",
        "            self.epsilon *= self.epsilon_decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAM54rfsZhrI"
      },
      "source": [
        "### Sokoban class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDvs7CzIQtO"
      },
      "source": [
        "#### SokobanEpisode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "pwHTyyAfZflp"
      },
      "outputs": [],
      "source": [
        "class SokobanEpsiode:\n",
        "    def __init__(self, isFixed=True, max_steps=500, sample_batch_size=32, \n",
        "                  episodes = 100, save_every=10,\n",
        "                  critic_lr=0.01, actor_lr=0.01, gamma=0.99, \n",
        "                  epsilon=0.99, epsilon_min=0.1, epsilon_decay=0.999,\n",
        "                  save_rewards=False, is_a2c_small=False):\n",
        "        \"\"\"\n",
        "        performs updates after a full episode\n",
        "        \"\"\"\n",
        "        self.saved_weights_dir =\"saved_weights_SokobanEpsiode_small\" if is_a2c_small else \"saved_weights_SokobanEpsiode\"\n",
        "        self.saved_rewards_dir = os.path.join(self.saved_weights_dir, \"rewards\")\n",
        "\n",
        "        if not os.path.exists(self.saved_weights_dir):\n",
        "          os.makedirs(self.saved_weights_dir)\n",
        "        if not os.path.exists(self.saved_rewards_dir):\n",
        "          os.makedirs(self.saved_rewards_dir)\n",
        "\n",
        "        self.sample_batch_size = sample_batch_size \n",
        "        self.episodes =  episodes\n",
        "        self.isFixed = isFixed\n",
        "        self.save_rewards = save_rewards\n",
        "        self.env = PushAndPullSokobanEnv(dim_room=(7, 7),num_boxes=1, max_steps=max_steps)\n",
        "\n",
        "        if self.isFixed:\n",
        "          random.seed(2)\n",
        "          _ = self.env.reset()\n",
        "        print_env_det(self.env)\n",
        "        \n",
        "        self.state_size        = (64,64,3) #self.env.observation_space.shape\n",
        "        self.action_size       = self.env.action_space.n\n",
        "        \n",
        "        # path to file where to save the rewards\n",
        "        self.rewards_file_path = os.path.join(self.saved_rewards_dir, f\"rewards_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}.pickle\")\n",
        "\n",
        "        if is_a2c_small:\n",
        "          self.a2c = A2C_small(state_size = self.state_size, action_size = self.action_size,\n",
        "                  critic_lr=critic_lr, actor_lr=actor_lr, gamma=gamma, \n",
        "                  epsilon=epsilon, epsilon_min=epsilon_min, epsilon_decay=epsilon_decay,\n",
        "                  weight_backup_critic=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_critic.h5\"),\n",
        "                  weight_backup_actor=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_actor.h5\"))\n",
        "\n",
        "        else:\n",
        "          self.a2c = A2C(state_size = self.state_size, action_size = self.action_size,\n",
        "                          critic_lr=critic_lr, actor_lr=actor_lr, gamma=gamma, \n",
        "                          epsilon=epsilon, epsilon_min=epsilon_min, epsilon_decay=epsilon_decay,\n",
        "                          weight_backup_critic=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_critic.h5\"),\n",
        "                          weight_backup_actor=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_actor.h5\"))\n",
        "        self.rewards        = []\n",
        "        self.steps        = []\n",
        "        self.save_every = save_every\n",
        "\n",
        "    def get_rewards(self):\n",
        "      return self.rewards\n",
        "\n",
        "    def get_steps(self):\n",
        "      return self.steps\n",
        "\n",
        "    def get_env(self):\n",
        "      return self.env\n",
        "    \n",
        "    def get_policy(self):\n",
        "      return self.a2c \n",
        "    \n",
        "    def get_isFixed(self):\n",
        "      return self.isFixed\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        try:\n",
        "            for index_episode in range(self.episodes):\n",
        "                total_reward = 0\n",
        "                if self.isFixed:\n",
        "                  random.seed(2)\n",
        "                else:\n",
        "                  random.seed()\n",
        "                state = self.env.reset()\n",
        "                if IS_TINY_RGB:\n",
        "                  state = self.env.render(mode='tiny_rgb_array')\n",
        "                state = preprocess_state(state, self.state_size)\n",
        "                done = False\n",
        "                index = 0\n",
        "                while not done:\n",
        "                    # self.env.render()\n",
        "                    action = self.a2c.act(state)\n",
        "\n",
        "                    old_box_location = find_box_location(self.env)\n",
        "\n",
        "                    next_state, reward, done, _ = self.env.step(action)\n",
        "                    \n",
        "                    if IS_REWARD_SHAPING and not done:\n",
        "                      new_box_location = find_box_location(self.env)\n",
        "                      target_location = list(self.env.box_mapping.keys())[0]\n",
        "                      reward = reward_shaping(reward, old_box_location, new_box_location, target_location)\n",
        "\n",
        "                    if IS_TINY_RGB:\n",
        "                      next_state = self.env.render(mode='tiny_rgb_array')\n",
        "                    next_state = preprocess_state(next_state, self.state_size)\n",
        "                    total_reward += reward\n",
        "                    # print(f\"took step: {action_translation(action)}\")\n",
        "                    self.a2c.remember(state, action, reward, next_state, done)\n",
        "                    state = next_state\n",
        "                    index += 1\n",
        "                print(f\"Episode {index_episode}, Steps: {index}, Reward:{total_reward}\")\n",
        "                self.a2c.replay(self.sample_batch_size, True)\n",
        "                self.steps.append(index)\n",
        "                self.rewards.append(float(\"{:.5f}\".format(total_reward)))\n",
        "                if index_episode % self.save_every == 0:\n",
        "                  self.a2c.save_model()\n",
        "                  if self.save_rewards:\n",
        "                    with open(self.rewards_file_path, 'wb') as f:\n",
        "                      pickle.dump(self.rewards, f)\n",
        "                  print(f'Average reward so far: {np.mean(self.rewards)}')\n",
        "                  print(f'Best reward so far: {np.max(self.rewards)}')\n",
        "\n",
        "        finally:\n",
        "            self.a2c.save_model()\n",
        "            if self.save_rewards:\n",
        "              with open(self.rewards_file_path, 'wb') as f:\n",
        "                pickle.dump(self.rewards, f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uUMgPuNvIbFv"
      },
      "source": [
        "#### SokobanStep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "e1Z0cIPxIObQ"
      },
      "outputs": [],
      "source": [
        "class SokobanStep:\n",
        "    def __init__(self, isFixed=True, max_steps=500, sample_batch_size=32, \n",
        "                  episodes = 100, save_every=10,\n",
        "                  critic_lr=0.01, actor_lr=0.01, gamma=0.99, \n",
        "                  epsilon=0.99, epsilon_min=0.1, epsilon_decay=0.999,\n",
        "                  save_rewards=False, is_a2c_small=False):\n",
        "        \"\"\"\n",
        "        performs updates after every step\n",
        "        \"\"\"\n",
        "        self.saved_weights_dir =\"saved_weights_SokobanStep_small\" if is_a2c_small else \"saved_weights_SokobanStep\"\n",
        "        self.saved_rewards_dir = os.path.join(self.saved_weights_dir, \"rewards\")\n",
        "\n",
        "        if not os.path.exists(self.saved_weights_dir):\n",
        "          os.makedirs(self.saved_weights_dir)\n",
        "        if not os.path.exists(self.saved_rewards_dir):\n",
        "          os.makedirs(self.saved_rewards_dir)\n",
        "\n",
        "        self.sample_batch_size = sample_batch_size \n",
        "        self.episodes =  episodes\n",
        "        self.isFixed = isFixed\n",
        "        self.save_rewards = save_rewards\n",
        "        self.env = PushAndPullSokobanEnv(dim_room=(7, 7),num_boxes=1, max_steps=max_steps)\n",
        "        self.replay_step_frequecny = 10\n",
        "\n",
        "        if self.isFixed:\n",
        "          random.seed(2)\n",
        "          _ = self.env.reset()\n",
        "        print_env_det(self.env)\n",
        "        \n",
        "        self.state_size        = (32,32,3) #self.env.observation_space.shape\n",
        "        self.action_size       = self.env.action_space.n\n",
        "\n",
        "        # path to file where to save the rewards\n",
        "        self.rewards_file_path = os.path.join(self.saved_rewards_dir, f\"rewards_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}.pickle\")\n",
        "\n",
        "\n",
        "        if is_a2c_small:\n",
        "          self.a2c = A2C_small(self.state_size, self.action_size,\n",
        "                  critic_lr=critic_lr, actor_lr=actor_lr, gamma=gamma, \n",
        "                  epsilon=epsilon, epsilon_min=epsilon_min, epsilon_decay=epsilon_decay,\n",
        "                  weight_backup_critic=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_critic.h5\"),\n",
        "                  weight_backup_actor=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_actor.h5\"))\n",
        "\n",
        "        else:\n",
        "          self.a2c = A2C(self.state_size, self.action_size,\n",
        "                          critic_lr=critic_lr, actor_lr=actor_lr, gamma=gamma, \n",
        "                          epsilon=epsilon, epsilon_min=epsilon_min, epsilon_decay=epsilon_decay,\n",
        "                          weight_backup_critic=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_critic.h5\"),\n",
        "                          weight_backup_actor=os.path.join(self.saved_weights_dir, f\"weight_state_size_{self.state_size[0]}_critic_lr_{str(critic_lr).replace('.', '_')}_actor_lr_{str(actor_lr).replace('.', '_')}_gamma_{str(gamma).replace('.', '_')}_epsilon_{str(epsilon).replace('.', '_')}_epsilon_min_{str(epsilon_min).replace('.', '_')}_epsilon_decay_{str(epsilon_decay).replace('.', '_')}_actor.h5\"))\n",
        "        self.rewards        = []\n",
        "        self.steps        = []\n",
        "        self.save_every = save_every\n",
        "\n",
        "    def get_rewards(self):\n",
        "      return self.rewards\n",
        "\n",
        "    def get_steps(self):\n",
        "      return self.steps\n",
        "\n",
        "    def get_env(self):\n",
        "      return self.env\n",
        "    \n",
        "    def get_policy(self):\n",
        "      return self.a2c \n",
        "    \n",
        "    def get_isFixed(self):\n",
        "      return self.isFixed\n",
        "    \n",
        "\n",
        "    def run(self):\n",
        "        try:\n",
        "            for index_episode in range(self.episodes):\n",
        "                total_reward = 0\n",
        "                if self.isFixed:\n",
        "                  random.seed(2)\n",
        "                else:\n",
        "                  random.seed()\n",
        "                state = self.env.reset()\n",
        "                if IS_TINY_RGB:\n",
        "                  state = self.env.render(mode='tiny_rgb_array')\n",
        "                state = preprocess_state(state, self.state_size)\n",
        "                done = False\n",
        "                index = 0\n",
        "                while not done:\n",
        "                  isNewEpisode = index == 0\n",
        "                  # self.env.render()\n",
        "                  action = self.a2c.act(state)\n",
        "\n",
        "                  old_box_location = find_box_location(self.env)\n",
        "\n",
        "                  next_state, reward, done, _ = self.env.step(action)\n",
        "\n",
        "\n",
        "                  if IS_REWARD_SHAPING and not done:\n",
        "                    new_box_location = find_box_location(self.env)\n",
        "                    target_location = list(self.env.box_mapping.keys())[0]\n",
        "                    reward = reward_shaping(reward, old_box_location, new_box_location, target_location)\n",
        "                  \n",
        "                  if IS_TINY_RGB:\n",
        "                    next_state = self.env.render(mode='tiny_rgb_array')\n",
        "                  next_state = preprocess_state(next_state, self.state_size)\n",
        "                  total_reward += reward\n",
        "                  # print(f\"took step: {action_translation(action)}\")\n",
        "                  self.a2c.remember(state, action, reward, next_state, done)\n",
        "                  state = next_state\n",
        "                  index += 1\n",
        "                  if index % self.replay_step_frequecny == 0:\n",
        "                    self.a2c.replay(self.sample_batch_size, isNewEpisode)\n",
        "\n",
        "                self.steps.append(index)\n",
        "                self.rewards.append(float(\"{:.5f}\".format(total_reward)))\n",
        "                print(f\"Episode {index_episode}, Steps: {index}, Reward:{total_reward}\")\n",
        "                if index_episode % self.save_every == 0:\n",
        "                  self.a2c.save_model()\n",
        "                  if self.save_rewards:\n",
        "                    with open(self.rewards_file_path, 'wb') as f:\n",
        "                      pickle.dump(self.rewards, f)\n",
        "                  print(f'Average reward so far: {np.mean(self.rewards)}')\n",
        "                  print(f'Best reward so far: {np.max(self.rewards)}')\n",
        "\n",
        "        finally:\n",
        "            self.a2c.save_model()\n",
        "            \n",
        "            if self.save_rewards:\n",
        "              with open(self.rewards_file_path, 'wb') as f:\n",
        "                pickle.dump(self.rewards, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAJXAZscdD8F"
      },
      "source": [
        "### run train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "RlcW6S__dGYf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "########################################################################################################\n",
            "\n",
            "default hyperparameters:\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_300 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_150 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_301 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_151 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_302 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_152 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_50 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_303 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_153 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_304 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_154 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_305 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_155 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_51 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 12, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 13, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 18, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 20, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 22, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 23, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 26, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 27, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 28, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 29, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 30, Steps: 500, Reward:-51.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.064516129032256\n",
            "Best reward so far: -51.0\n",
            "Episode 31, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 32, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 33, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 34, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 35, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 36, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 37, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 38, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 39, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 40, Steps: 500, Reward:-52.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.09756097560975\n",
            "Best reward so far: -51.0\n",
            "Episode 41, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 42, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 43, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 44, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 45, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 46, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 47, Steps: 500, Reward:-50.000000000000455\n",
            "Episode 48, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 49, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.80392156862745\n",
            "Best reward so far: -48.0\n",
            "Episode 51, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 52, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 53, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 54, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 55, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 56, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 57, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 58, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 60, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.67213114754098\n",
            "Best reward so far: -48.0\n",
            "Episode 61, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 62, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 63, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 64, Steps: 369, Reward:-23.90000000000022\n",
            "Episode 65, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 66, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 67, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 68, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 69, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 70, Steps: 500, Reward:-49.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.069014084507046\n",
            "Best reward so far: -23.9\n",
            "Episode 71, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 72, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 73, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 74, Steps: 445, Reward:-31.500000000000348\n",
            "Episode 75, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 76, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 77, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 78, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 79, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 80, Steps: 500, Reward:-49.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.52345679012346\n",
            "Best reward so far: -23.9\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 82, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 83, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 84, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 85, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 86, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 87, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 88, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 89, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 90, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.79560439560439\n",
            "Best reward so far: -23.9\n",
            "Episode 91, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 92, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 93, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 94, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 95, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 96, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 97, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 98, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 99, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "\n",
            "########################################################################################################\n",
            "\n",
            "gammas:\n",
            "\n",
            "**HYPERPARAMETER**: gamma=0.8\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_306 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_156 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_307 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_157 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_308 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_158 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_52 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_309 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_159 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_310 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_160 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_311 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_161 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_53 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 12, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 13, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 18, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 20, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 22, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 23, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 26, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 27, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 28, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 29, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 30, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.903225806451616\n",
            "Best reward so far: -49.0\n",
            "Episode 31, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 32, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 33, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 34, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 35, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 36, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 37, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 38, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 39, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 40, Steps: 500, Reward:-51.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.926829268292686\n",
            "Best reward so far: -49.0\n",
            "Episode 41, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 42, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 43, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 44, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 45, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 46, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 47, Steps: 500, Reward:-50.000000000000455\n",
            "Episode 48, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 49, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 50, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.92156862745098\n",
            "Best reward so far: -49.0\n",
            "Episode 51, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 52, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 53, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 54, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 55, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 56, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 57, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 58, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 59, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 60, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.37049180327869\n",
            "Best reward so far: -24.6\n",
            "Episode 61, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 62, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 63, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 64, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 65, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 66, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 67, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 68, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 69, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 70, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.5718309859155\n",
            "Best reward so far: -24.6\n",
            "Episode 71, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 72, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 73, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 74, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 75, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 76, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 77, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 78, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 79, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 80, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.748148148148154\n",
            "Best reward so far: -24.6\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 82, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 83, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 84, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 85, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 86, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 87, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 88, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 89, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 90, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.8967032967033\n",
            "Best reward so far: -24.6\n",
            "Episode 91, Steps: 500, Reward:-49.000000000000476\n",
            "Episode 92, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 93, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 94, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 95, Steps: 500, Reward:-50.000000000000476\n",
            "Episode 96, Steps: 500, Reward:-52.000000000000476\n",
            "Episode 97, Steps: 500, Reward:-52.000000000000476\n",
            "Episode 98, Steps: 500, Reward:-52.000000000000476\n",
            "Episode 99, Steps: 500, Reward:-52.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: gamma=0.85\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_312 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_162 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_313 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_163 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_314 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_164 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_54 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_164 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_315 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_165 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_316 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_166 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_317 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_167 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_55 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 12, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 13, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 14, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 15, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 16, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 17, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 18, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 19, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 20, Steps: 500, Reward:-48.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.19047619047619\n",
            "Best reward so far: -48.0\n",
            "Episode 21, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 22, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 23, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 24, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 25, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 26, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 27, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 28, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 29, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 30, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.74193548387097\n",
            "Best reward so far: -48.0\n",
            "Episode 31, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 32, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 33, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 34, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 35, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 36, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 37, Steps: 500, Reward:-49.0000000000005\n",
            "Episode 38, Steps: 500, Reward:-49.0000000000005\n",
            "Episode 39, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 40, Steps: 500, Reward:-51.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.80487804878049\n",
            "Best reward so far: -48.0\n",
            "Episode 41, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 42, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 43, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 44, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 45, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 46, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 47, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 48, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 49, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 50, Steps: 500, Reward:-51.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.96078431372549\n",
            "Best reward so far: -48.0\n",
            "Episode 51, Steps: 500, Reward:-52.00000000000046\n",
            "Episode 52, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 53, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 54, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 55, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 56, Steps: 500, Reward:-50.000000000000476\n",
            "Episode 57, Steps: 500, Reward:-49.000000000000476\n",
            "Episode 58, Steps: 500, Reward:-50.000000000000476\n",
            "Episode 59, Steps: 500, Reward:-50.000000000000476\n",
            "Episode 60, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.98360655737705\n",
            "Best reward so far: -48.0\n",
            "Episode 61, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 62, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 63, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 64, Steps: 500, Reward:-52.00000000000046\n",
            "Episode 65, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 66, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 67, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 68, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 69, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 70, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.014084507042256\n",
            "Best reward so far: -48.0\n",
            "Episode 71, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 72, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 73, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 74, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 75, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 76, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 77, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 78, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 79, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 80, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.06172839506173\n",
            "Best reward so far: -48.0\n",
            "Episode 81, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 82, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 83, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 84, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 85, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 86, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 87, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 88, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 89, Steps: 373, Reward:-24.300000000000274\n",
            "Episode 90, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.761538461538464\n",
            "Best reward so far: -24.3\n",
            "Episode 91, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 92, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 93, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 94, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 95, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 96, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 97, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 98, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 99, Steps: 500, Reward:-48.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: gamma=0.9\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_318 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_168 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_319 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_169 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_320 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_170 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_56 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_168 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_321 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_171 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_322 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_172 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_323 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_173 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_57 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_172 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_173 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 6, Steps: 342, Reward:-21.20000000000021\n",
            "Episode 7, Steps: 342, Reward:-21.20000000000021\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.58181818181818\n",
            "Best reward so far: -21.2\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 12, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 13, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 14, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 15, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 16, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 17, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 18, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 19, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 20, Steps: 500, Reward:-49.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.25714285714285\n",
            "Best reward so far: -21.2\n",
            "Episode 21, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 22, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 23, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 24, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 25, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 26, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 27, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 28, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 29, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 30, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.9483870967742\n",
            "Best reward so far: -21.2\n",
            "Episode 31, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 32, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 33, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 34, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 35, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 36, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 37, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 38, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 39, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 40, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.107317073170734\n",
            "Best reward so far: -21.2\n",
            "Episode 41, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 42, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 43, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 44, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 45, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 46, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 47, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 48, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 49, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.36078431372549\n",
            "Best reward so far: -21.2\n",
            "Episode 51, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 52, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 53, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 54, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 55, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 56, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 57, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 58, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 59, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 60, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.747540983606555\n",
            "Best reward so far: -21.2\n",
            "Episode 61, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 62, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 63, Steps: 439, Reward:-30.90000000000034\n",
            "Episode 64, Steps: 369, Reward:-23.90000000000024\n",
            "Episode 65, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 66, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 67, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 68, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 69, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 70, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.44225352112676\n",
            "Best reward so far: -21.2\n",
            "Episode 71, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 72, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 73, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 74, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 75, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 76, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 77, Steps: 500, Reward:-49.00000000000041\n",
            "Episode 78, Steps: 372, Reward:-24.200000000000223\n",
            "Episode 79, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 80, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.40246913580247\n",
            "Best reward so far: -21.2\n",
            "Episode 81, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 82, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 83, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 84, Steps: 500, Reward:-52.00000000000046\n",
            "Episode 85, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 86, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 87, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 88, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 89, Steps: 386, Reward:-25.60000000000028\n",
            "Episode 90, Steps: 500, Reward:-51.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.44175824175825\n",
            "Best reward so far: -21.2\n",
            "Episode 91, Steps: 368, Reward:-23.80000000000024\n",
            "Episode 92, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 93, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 94, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 95, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 96, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 97, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 98, Steps: 389, Reward:-25.90000000000027\n",
            "Episode 99, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: gamma=0.95\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_324 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_174 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_325 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_175 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_326 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_176 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_58 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_327 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_177 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_328 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_178 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_329 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_179 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_59 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 12, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 13, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 18, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 20, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 22, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 23, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 26, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 27, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 28, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 29, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 30, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.935483870967744\n",
            "Best reward so far: -50.0\n",
            "Episode 31, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 32, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 33, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 34, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 35, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 36, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 37, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 38, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 39, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 40, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.73170731707317\n",
            "Best reward so far: -50.0\n",
            "Episode 41, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 42, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 43, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 44, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 45, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 46, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 47, Steps: 500, Reward:-50.000000000000455\n",
            "Episode 48, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 49, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.627450980392155\n",
            "Best reward so far: -48.0\n",
            "Episode 51, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 52, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 53, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 54, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 55, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 56, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 57, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 58, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 60, Steps: 500, Reward:-50.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.52459016393443\n",
            "Best reward so far: -48.0\n",
            "Episode 61, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 62, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 63, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 64, Steps: 500, Reward:-49.000000000000405\n",
            "Episode 65, Steps: 500, Reward:-49.00000000000045\n",
            "Episode 66, Steps: 500, Reward:-49.00000000000045\n",
            "Episode 67, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 68, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 69, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 70, Steps: 500, Reward:-49.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.36619718309859\n",
            "Best reward so far: -48.0\n",
            "Episode 71, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 72, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 73, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 74, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 75, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 76, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 77, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 78, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 79, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 80, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.32098765432099\n",
            "Best reward so far: -48.0\n",
            "Episode 81, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 82, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 83, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 84, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 85, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 86, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 87, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 88, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 89, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 90, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.285714285714285\n",
            "Best reward so far: -48.0\n",
            "Episode 91, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 92, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 93, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 94, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 95, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 96, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 97, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 98, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 99, Steps: 500, Reward:-51.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: gamma=0.999\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_330 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_180 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_331 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_181 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_332 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_182 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_60 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_180 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_333 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_183 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_334 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_184 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_335 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_185 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_61 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_183 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_184 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_185 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 12, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 13, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 18, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 20, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 22, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 23, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 26, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 27, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 28, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 29, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 30, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.935483870967744\n",
            "Best reward so far: -50.0\n",
            "Episode 31, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 32, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 33, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 34, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 35, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 36, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 37, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 38, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 39, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 40, Steps: 500, Reward:-48.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.68292682926829\n",
            "Best reward so far: -48.0\n",
            "Episode 41, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 42, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 43, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 44, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 45, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 46, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 47, Steps: 372, Reward:-24.200000000000244\n",
            "Episode 48, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 49, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 50, Steps: 500, Reward:-49.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.92549019607843\n",
            "Best reward so far: -24.2\n",
            "Episode 51, Steps: 375, Reward:-24.50000000000025\n",
            "Episode 52, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 53, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 54, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 55, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 56, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 57, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 58, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 59, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 60, Steps: 500, Reward:-51.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.07049180327869\n",
            "Best reward so far: -24.2\n",
            "Episode 61, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 62, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 63, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 64, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 65, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 66, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 67, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 68, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 69, Steps: 186, Reward:-5.599999999999961\n",
            "Episode 70, Steps: 500, Reward:-52.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -46.94225352112676\n",
            "Best reward so far: -5.6\n",
            "Episode 71, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 72, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 73, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 74, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 75, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 76, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 77, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 78, Steps: 372, Reward:-24.200000000000223\n",
            "Episode 79, Steps: 372, Reward:-24.200000000000223\n",
            "Episode 80, Steps: 372, Reward:-24.200000000000223\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -46.30246913580247\n",
            "Best reward so far: -5.6\n",
            "Episode 81, Steps: 372, Reward:-24.200000000000223\n",
            "Episode 82, Steps: 372, Reward:-24.200000000000223\n",
            "Episode 83, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 84, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 85, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 86, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 87, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 88, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 89, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 90, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -46.15274725274725\n",
            "Best reward so far: -5.6\n",
            "Episode 91, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 92, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 93, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 94, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 95, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 96, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 97, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 98, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 99, Steps: 500, Reward:-52.00000000000047\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "\n",
            "########################################################################################################\n",
            "\n",
            "epsilons:\n",
            "\n",
            "**HYPERPARAMETER**: epsilon=0.9\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_336 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_186 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_337 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_187 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_338 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_188 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_62 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_188 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_339 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_189 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_340 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_190 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_341 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_191 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_63 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_190 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_191 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.0\n",
            "Best reward so far: -50.0\n",
            "Episode 1, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 2, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 3, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 4, Steps: 391, Reward:-26.10000000000027\n",
            "Episode 5, Steps: 391, Reward:-26.10000000000027\n",
            "Episode 6, Steps: 391, Reward:-26.10000000000027\n",
            "Episode 7, Steps: 391, Reward:-26.10000000000027\n",
            "Episode 8, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 9, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 10, Steps: 303, Reward:-17.300000000000146\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -38.24545454545454\n",
            "Best reward so far: -17.3\n",
            "Episode 11, Steps: 303, Reward:-17.300000000000146\n",
            "Episode 12, Steps: 190, Reward:-5.999999999999984\n",
            "Episode 13, Steps: 190, Reward:-5.999999999999984\n",
            "Episode 14, Steps: 190, Reward:-5.999999999999984\n",
            "Episode 15, Steps: 190, Reward:-5.999999999999984\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 17, Steps: 470, Reward:-34.00000000000043\n",
            "Episode 18, Steps: 500, Reward:-48.000000000000405\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000048\n",
            "Episode 20, Steps: 500, Reward:-49.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -33.095238095238095\n",
            "Best reward so far: -6.0\n",
            "Episode 21, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 22, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 23, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 24, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 25, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 26, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 27, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 28, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 29, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 30, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -38.516129032258064\n",
            "Best reward so far: -6.0\n",
            "Episode 31, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 32, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 33, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 34, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 35, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 36, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 37, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 38, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 39, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 40, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -41.24390243902439\n",
            "Best reward so far: -6.0\n",
            "Episode 41, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 42, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 43, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 44, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 45, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 46, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 47, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 48, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 49, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -42.96078431372549\n",
            "Best reward so far: -6.0\n",
            "Episode 51, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 52, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 53, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 54, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 55, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 56, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 57, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 58, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 60, Steps: 500, Reward:-49.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -44.09836065573771\n",
            "Best reward so far: -6.0\n",
            "Episode 61, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 62, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 63, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 64, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 65, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 66, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 67, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 68, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 69, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 70, Steps: 500, Reward:-51.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.04225352112676\n",
            "Best reward so far: -6.0\n",
            "Episode 71, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 72, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 73, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 74, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 75, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 76, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 77, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 78, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 79, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 80, Steps: 500, Reward:-50.00000000000043\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.69135802469136\n",
            "Best reward so far: -6.0\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000043\n",
            "Episode 82, Steps: 500, Reward:-50.00000000000043\n",
            "Episode 83, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 84, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 85, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 86, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 87, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 88, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 89, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 90, Steps: 500, Reward:-51.00000000000043\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -46.252747252747255\n",
            "Best reward so far: -6.0\n",
            "Episode 91, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 92, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 93, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 94, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 95, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 96, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 97, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 98, Steps: 500, Reward:-51.00000000000043\n",
            "Episode 99, Steps: 500, Reward:-51.00000000000043\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: epsilon=0.95\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_342 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_192 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_343 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_193 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_344 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_194 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_64 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_192 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_345 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_195 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_346 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_196 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_347 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_197 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_65 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_196 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-48.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.0\n",
            "Best reward so far: -48.0\n",
            "Episode 1, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 2, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 3, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 4, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 5, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 6, Steps: 500, Reward:-48.000000000000455\n",
            "Episode 7, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 8, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 9, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 10, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.09090909090909\n",
            "Best reward so far: -48.0\n",
            "Episode 11, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 12, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 13, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 14, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 15, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 16, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 17, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 18, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 19, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 20, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.523809523809526\n",
            "Best reward so far: -48.0\n",
            "Episode 21, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 22, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 23, Steps: 369, Reward:-23.90000000000022\n",
            "Episode 24, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 25, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 26, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 27, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 28, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 29, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 30, Steps: 371, Reward:-24.10000000000028\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -42.9774193548387\n",
            "Best reward so far: -23.9\n",
            "Episode 31, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 32, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 33, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 34, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 35, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 36, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 37, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 38, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 39, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 40, Steps: 500, Reward:-50.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -43.426829268292686\n",
            "Best reward so far: -23.9\n",
            "Episode 41, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 42, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 43, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 44, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 45, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 46, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 47, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 48, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 49, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 50, Steps: 500, Reward:-48.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -44.57843137254902\n",
            "Best reward so far: -23.9\n",
            "Episode 51, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 52, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 53, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 54, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 55, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 56, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 57, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 58, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 59, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 60, Steps: 500, Reward:-49.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.15573770491803\n",
            "Best reward so far: -23.9\n",
            "Episode 61, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 62, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 63, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 64, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 65, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 66, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 67, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 68, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 69, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 70, Steps: 470, Reward:-34.000000000000384\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -44.21830985915493\n",
            "Best reward so far: -23.9\n",
            "Episode 71, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 72, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 73, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 74, Steps: 470, Reward:-34.000000000000384\n",
            "Episode 75, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 76, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 77, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 78, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 79, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 80, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -44.129629629629626\n",
            "Best reward so far: -23.9\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 82, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 83, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 84, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 85, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 86, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 87, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 88, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 89, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 90, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -44.81868131868132\n",
            "Best reward so far: -23.9\n",
            "Episode 91, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 92, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 93, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 94, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 95, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 96, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 97, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 98, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 99, Steps: 500, Reward:-51.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: epsilon=0.999\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_348 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_198 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_349 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_199 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_350 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_200 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_66 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_200 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_351 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_201 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_352 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_202 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_353 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_203 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_67 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 12, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 13, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 14, Steps: 500, Reward:-50.00000000000043\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 16, Steps: 342, Reward:-21.20000000000021\n",
            "Episode 17, Steps: 342, Reward:-21.20000000000021\n",
            "Episode 18, Steps: 343, Reward:-21.30000000000021\n",
            "Episode 19, Steps: 343, Reward:-21.30000000000021\n",
            "Episode 20, Steps: 500, Reward:-50.00000000000043\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.23809523809524\n",
            "Best reward so far: -21.2\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 22, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 23, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 24, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 25, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 26, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 27, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 28, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 29, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 30, Steps: 500, Reward:-49.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -46.41935483870968\n",
            "Best reward so far: -21.2\n",
            "Episode 31, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 32, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 33, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 34, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 35, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 36, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 37, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 38, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 39, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 40, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.34146341463415\n",
            "Best reward so far: -21.2\n",
            "Episode 41, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 42, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 43, Steps: 500, Reward:-49.0000000000005\n",
            "Episode 44, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 45, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 46, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 47, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 48, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 49, Steps: 500, Reward:-53.0000000000005\n",
            "Episode 50, Steps: 500, Reward:-50.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.92156862745098\n",
            "Best reward so far: -21.2\n",
            "Episode 51, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 52, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 53, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 54, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 55, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 56, Steps: 500, Reward:-49.000000000000476\n",
            "Episode 57, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 58, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 59, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 60, Steps: 500, Reward:-48.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.31147540983606\n",
            "Best reward so far: -21.2\n",
            "Episode 61, Steps: 500, Reward:-52.00000000000046\n",
            "Episode 62, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 63, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 64, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 65, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 66, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 67, Steps: 500, Reward:-52.000000000000476\n",
            "Episode 68, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 69, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 70, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.66197183098591\n",
            "Best reward so far: -21.2\n",
            "Episode 71, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 72, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 73, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 74, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 75, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 76, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 77, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 78, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 79, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 80, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.851851851851855\n",
            "Best reward so far: -21.2\n",
            "Episode 81, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 82, Steps: 500, Reward:-49.000000000000476\n",
            "Episode 83, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 84, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 85, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 86, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 87, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 88, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 89, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 90, Steps: 500, Reward:-50.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -48.97802197802198\n",
            "Best reward so far: -21.2\n",
            "Episode 91, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 92, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 93, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 94, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 95, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 96, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 97, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 98, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 99, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "\n",
            "########################################################################################################\n",
            "\n",
            "epsilon_mins:\n",
            "\n",
            "**HYPERPARAMETER**: epsilon_min=0.05\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_354 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_204 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_355 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_205 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_356 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_206 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_68 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_204 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_205 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_357 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_207 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_358 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_208 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_359 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_209 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_69 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_208 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 12, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 13, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 18, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 20, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 22, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 23, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 26, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 27, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 28, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 29, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 30, Steps: 500, Reward:-51.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.064516129032256\n",
            "Best reward so far: -51.0\n",
            "Episode 31, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 32, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 33, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 34, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 35, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 36, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 37, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 38, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 39, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 40, Steps: 500, Reward:-52.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.09756097560975\n",
            "Best reward so far: -51.0\n",
            "Episode 41, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 42, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 43, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 44, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 45, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 46, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 47, Steps: 500, Reward:-50.000000000000455\n",
            "Episode 48, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 49, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.80392156862745\n",
            "Best reward so far: -48.0\n",
            "Episode 51, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 52, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 53, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 54, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 55, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 56, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 57, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 58, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 60, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.67213114754098\n",
            "Best reward so far: -48.0\n",
            "Episode 61, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 62, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 63, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 64, Steps: 369, Reward:-23.90000000000022\n",
            "Episode 65, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 66, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 67, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 68, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 69, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 70, Steps: 500, Reward:-49.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.069014084507046\n",
            "Best reward so far: -23.9\n",
            "Episode 71, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 72, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 73, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 74, Steps: 445, Reward:-31.500000000000348\n",
            "Episode 75, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 76, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 77, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 78, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 79, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 80, Steps: 500, Reward:-49.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.52345679012346\n",
            "Best reward so far: -23.9\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 82, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 83, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 84, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 85, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 86, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 87, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 88, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 89, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 90, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.79560439560439\n",
            "Best reward so far: -23.9\n",
            "Episode 91, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 92, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 93, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 94, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 95, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 96, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 97, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 98, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 99, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: epsilon_min=0.15\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_360 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_210 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_361 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_211 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_362 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_212 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_70 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_212 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_363 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_213 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_364 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_214 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_365 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_215 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_71 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 12, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 13, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 18, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 20, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 22, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 23, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 26, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 27, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 28, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 29, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 30, Steps: 500, Reward:-51.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.064516129032256\n",
            "Best reward so far: -51.0\n",
            "Episode 31, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 32, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 33, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 34, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 35, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 36, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 37, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 38, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 39, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 40, Steps: 500, Reward:-52.0000000000005\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.09756097560975\n",
            "Best reward so far: -51.0\n",
            "Episode 41, Steps: 500, Reward:-52.0000000000005\n",
            "Episode 42, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 43, Steps: 500, Reward:-50.0000000000005\n",
            "Episode 44, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 45, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 46, Steps: 500, Reward:-48.0000000000005\n",
            "Episode 47, Steps: 500, Reward:-50.000000000000455\n",
            "Episode 48, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 49, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.80392156862745\n",
            "Best reward so far: -48.0\n",
            "Episode 51, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 52, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 53, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 54, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 55, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 56, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 57, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 58, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 60, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.67213114754098\n",
            "Best reward so far: -48.0\n",
            "Episode 61, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 62, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 63, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 64, Steps: 369, Reward:-23.90000000000022\n",
            "Episode 65, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 66, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 67, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 68, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 69, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 70, Steps: 500, Reward:-49.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.069014084507046\n",
            "Best reward so far: -23.9\n",
            "Episode 71, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 72, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 73, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 74, Steps: 445, Reward:-31.500000000000348\n",
            "Episode 75, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 76, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 77, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 78, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 79, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 80, Steps: 500, Reward:-49.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.52345679012346\n",
            "Best reward so far: -23.9\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 82, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 83, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 84, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 85, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 86, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 87, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 88, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 89, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 90, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.79560439560439\n",
            "Best reward so far: -23.9\n",
            "Episode 91, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 92, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 93, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 94, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 95, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 96, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 97, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 98, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 99, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "\n",
            "########################################################################################################\n",
            "\n",
            "epsilon_decays:\n",
            "\n",
            "**HYPERPARAMETER**: epsilon_decay=0.99\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_366 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_216 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_367 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_217 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_368 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_218 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_72 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_216 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_369 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_219 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_370 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_220 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_371 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_221 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_73 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 2, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 3, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 5, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 6, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 7, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 8, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 9, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 10, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.45454545454545\n",
            "Best reward so far: -50.0\n",
            "Episode 11, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 12, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 13, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 14, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 15, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 16, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 17, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 18, Steps: 500, Reward:-49.000000000000405\n",
            "Episode 19, Steps: 424, Reward:-29.40000000000032\n",
            "Episode 20, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.25714285714286\n",
            "Best reward so far: -29.4\n",
            "Episode 21, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 22, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 23, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 24, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 25, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 26, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 27, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 28, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 29, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 30, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.722580645161294\n",
            "Best reward so far: -29.4\n",
            "Episode 31, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 32, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 33, Steps: 272, Reward:-14.20000000000009\n",
            "Episode 34, Steps: 500, Reward:-49.00000000000041\n",
            "Episode 35, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 36, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 37, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 38, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 39, Steps: 294, Reward:-16.40000000000012\n",
            "Episode 40, Steps: 312, Reward:-18.200000000000145\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.37073170731708\n",
            "Best reward so far: -14.2\n",
            "Episode 41, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 42, Steps: 467, Reward:-33.7000000000004\n",
            "Episode 43, Steps: 500, Reward:-52.00000000000045\n",
            "Episode 44, Steps: 427, Reward:-29.70000000000031\n",
            "Episode 45, Steps: 325, Reward:-19.500000000000163\n",
            "Episode 46, Steps: 316, Reward:-18.60000000000015\n",
            "Episode 47, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 48, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 49, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-52.00000000000048\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -46.1313725490196\n",
            "Best reward so far: -14.2\n",
            "Episode 51, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 52, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 53, Steps: 357, Reward:-22.70000000000021\n",
            "Episode 54, Steps: 363, Reward:-23.300000000000217\n",
            "Episode 55, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 56, Steps: 500, Reward:-48.00000000000041\n",
            "Episode 57, Steps: 500, Reward:-48.00000000000041\n",
            "Episode 58, Steps: 390, Reward:-26.000000000000256\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000041\n",
            "Episode 60, Steps: 375, Reward:-24.50000000000025\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.01967213114754\n",
            "Best reward so far: -14.2\n",
            "Episode 61, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 62, Steps: 398, Reward:-26.80000000000028\n",
            "Episode 63, Steps: 399, Reward:-26.900000000000283\n",
            "Episode 64, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 65, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 66, Steps: 399, Reward:-26.900000000000283\n",
            "Episode 67, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 68, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 69, Steps: 500, Reward:-49.000000000000405\n",
            "Episode 70, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -44.673239436619724\n",
            "Best reward so far: -14.2\n",
            "Episode 71, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 72, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 73, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 74, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 75, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 76, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 77, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 78, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 79, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 80, Steps: 500, Reward:-50.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.34320987654321\n",
            "Best reward so far: -14.2\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000045\n",
            "Episode 82, Steps: 500, Reward:-52.000000000000476\n",
            "Episode 83, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 84, Steps: 500, Reward:-48.00000000000041\n",
            "Episode 85, Steps: 500, Reward:-48.00000000000044\n",
            "Episode 86, Steps: 406, Reward:-27.600000000000307\n",
            "Episode 87, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 88, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 89, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 90, Steps: 500, Reward:-50.000000000000426\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -45.61978021978022\n",
            "Best reward so far: -14.2\n",
            "Episode 91, Steps: 129, Reward:0.10000000000002274\n",
            "Episode 92, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 93, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 94, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 95, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 96, Steps: 500, Reward:-49.000000000000426\n",
            "Episode 97, Steps: 500, Reward:-48.000000000000426\n",
            "Episode 98, Steps: 500, Reward:-48.00000000000041\n",
            "Episode 99, Steps: 500, Reward:-48.00000000000042\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\n",
            "**HYPERPARAMETER**: epsilon_decay=0.995\n",
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_372 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_222 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_373 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_223 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_374 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_224 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_74 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_375 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_225 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_376 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_226 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_377 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_227 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_75 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,109\n",
            "Trainable params: 620,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 4, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 5, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 6, Steps: 500, Reward:-51.0000000000005\n",
            "Episode 7, Steps: 500, Reward:-52.000000000000426\n",
            "Episode 8, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 9, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 10, Steps: 500, Reward:-50.00000000000048\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.72727272727273\n",
            "Best reward so far: -50.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000048\n",
            "Episode 12, Steps: 500, Reward:-50.00000000000048\n",
            "Episode 13, Steps: 500, Reward:-51.00000000000048\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000048\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000048\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000048\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000048\n",
            "Episode 18, Steps: 500, Reward:-50.000000000000405\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000047\n",
            "Episode 20, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.76190476190476\n",
            "Best reward so far: -50.0\n",
            "Episode 21, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 22, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 23, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 26, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 27, Steps: 381, Reward:-25.10000000000027\n",
            "Episode 28, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 29, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 30, Steps: 500, Reward:-48.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.87419354838709\n",
            "Best reward so far: -25.1\n",
            "Episode 31, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 32, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 33, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 34, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 35, Steps: 500, Reward:-52.000000000000476\n",
            "Episode 36, Steps: 500, Reward:-50.00000000000047\n",
            "Episode 37, Steps: 500, Reward:-50.00000000000047\n",
            "Episode 38, Steps: 500, Reward:-50.00000000000047\n",
            "Episode 39, Steps: 500, Reward:-49.00000000000047\n",
            "Episode 40, Steps: 500, Reward:-49.000000000000405\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.953658536585365\n",
            "Best reward so far: -25.1\n",
            "Episode 41, Steps: 500, Reward:-49.00000000000045\n",
            "Episode 42, Steps: 500, Reward:-49.00000000000045\n",
            "Episode 43, Steps: 500, Reward:-51.000000000000426\n",
            "Episode 44, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 45, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 46, Steps: 500, Reward:-49.000000000000405\n",
            "Episode 47, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 48, Steps: 500, Reward:-49.00000000000044\n",
            "Episode 49, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 50, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -49.903921568627446\n",
            "Best reward so far: -25.1\n",
            "Episode 51, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 52, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 53, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 54, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 55, Steps: 500, Reward:-51.00000000000044\n",
            "Episode 56, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 57, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 58, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 60, Steps: 500, Reward:-52.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.0672131147541\n",
            "Best reward so far: -25.1\n",
            "Episode 61, Steps: 262, Reward:-13.200000000000076\n",
            "Episode 62, Steps: 262, Reward:-13.200000000000076\n",
            "Episode 63, Steps: 500, Reward:-50.00000000000043\n",
            "Episode 64, Steps: 500, Reward:-50.00000000000043\n",
            "Episode 65, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 66, Steps: 500, Reward:-52.00000000000044\n",
            "Episode 67, Steps: 500, Reward:-50.000000000000426\n",
            "Episode 68, Steps: 500, Reward:-49.00000000000043\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[131], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m**HYPERPARAMETER**: epsilon_decay=\u001b[39m\u001b[39m{\u001b[39;00mepsilon_decay\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m     sokoban \u001b[39m=\u001b[39m SokobanEpsiode(epsilon_decay\u001b[39m=\u001b[39mepsilon_decay, is_a2c_small\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m     sokoban\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     57\u001b[0m \u001b[39m# sokoban = SokobanEpsiode()\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# sokoban.run()\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[129], line 84\u001b[0m, in \u001b[0;36mSokobanEpsiode.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m     83\u001b[0m     \u001b[39m# self.env.render()\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ma2c\u001b[39m.\u001b[39;49mact(state)\n\u001b[1;32m     86\u001b[0m     old_box_location \u001b[39m=\u001b[39m find_box_location(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv)\n\u001b[1;32m     88\u001b[0m     next_state, reward, done, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n",
            "Cell \u001b[0;32mIn[130], line 99\u001b[0m, in \u001b[0;36mA2C_small.act\u001b[0;34m(self, state, curr_env)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mreturn\u001b[39;00m random\u001b[39m.\u001b[39mrandrange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_size)\n\u001b[1;32m     98\u001b[0m state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_size[\u001b[39m0\u001b[39m],\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_size[\u001b[39m1\u001b[39m],\u001b[39m3\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m act_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor\u001b[39m.\u001b[39;49mpredict(state, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m ONLY_PERMITTED_ACTIONS:\n\u001b[1;32m    101\u001b[0m   act_values[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m i \u001b[39min\u001b[39;00m curr_allowed_actions \u001b[39melse\u001b[39;00m elem \u001b[39mfor\u001b[39;00m i,elem \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(act_values[\u001b[39m0\u001b[39m])]\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/keras/engine/training.py:2317\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2309\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2310\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2311\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2314\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2315\u001b[0m         )\n\u001b[0;32m-> 2317\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2318\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2319\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2320\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2321\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2322\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2323\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2324\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2325\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2326\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2327\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2328\u001b[0m )\n\u001b[1;32m   2330\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/keras/engine/data_adapter.py:1579\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1578\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1579\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/keras/engine/data_adapter.py:1259\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1258\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1260\u001b[0m     x,\n\u001b[1;32m   1261\u001b[0m     y,\n\u001b[1;32m   1262\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1263\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1264\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1265\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1266\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1267\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1268\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1269\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1270\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1271\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1272\u001b[0m )\n\u001b[1;32m   1274\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/keras/engine/data_adapter.py:306\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[1;32m    301\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[1;32m    308\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    309\u001b[0m     \u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2294\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2292\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2293\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2294\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2296\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2297\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   2298\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2301\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2302\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5505\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5499\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m   5500\u001b[0m     map_func,\n\u001b[1;32m   5501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformation_name(),\n\u001b[1;32m   5502\u001b[0m     dataset\u001b[39m=\u001b[39minput_dataset,\n\u001b[1;32m   5503\u001b[0m     use_legacy_function\u001b[39m=\u001b[39muse_legacy_function)\n\u001b[1;32m   5504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m-> 5505\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mmap_dataset(\n\u001b[1;32m   5506\u001b[0m     input_dataset\u001b[39m.\u001b[39;49m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   5507\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_func\u001b[39m.\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs,\n\u001b[1;32m   5508\u001b[0m     f\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_func\u001b[39m.\u001b[39;49mfunction,\n\u001b[1;32m   5509\u001b[0m     use_inter_op_parallelism\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_inter_op_parallelism,\n\u001b[1;32m   5510\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preserve_cardinality,\n\u001b[1;32m   5511\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_common_args)\n\u001b[1;32m   5512\u001b[0m \u001b[39msuper\u001b[39m(MapDataset, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(input_dataset, variant_tensor)\n",
            "File \u001b[0;32m~/anaconda3/envs/RL_hw/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3460\u001b[0m, in \u001b[0;36mmap_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, preserve_cardinality, metadata, name)\u001b[0m\n\u001b[1;32m   3458\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3459\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3460\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3461\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMapDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, input_dataset, other_arguments, \u001b[39m\"\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m, f,\n\u001b[1;32m   3462\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types, \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes,\n\u001b[1;32m   3463\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39muse_inter_op_parallelism\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_inter_op_parallelism,\n\u001b[1;32m   3464\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mpreserve_cardinality\u001b[39;49m\u001b[39m\"\u001b[39;49m, preserve_cardinality, \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m, metadata)\n\u001b[1;32m   3465\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3466\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "gammas = [0.8, 0.85, 0.9, 0.95, 0.999] # [0.8, 0.85, 0.9, 0.95, 0.99, 0.999]\n",
        "critic_lrs = [0.001, 0.1] #[0.001, 0.01, 0.1]\n",
        "actor_lrs = [0.001, 0.1] #[0.001, 0.01, 0.1]\n",
        "epsilons = [0.9, 0.95, 0.999] #[0.9, 0.95, 0.99, 0.999]\n",
        "epsilon_mins = [0.05, 0.15] #[0.05, 0.1, 0.15]\n",
        "epsilon_decays = [0.99, 0.995, 0.9999] #[0.99, 0.995, 0.999, 0.9999]\n",
        "\n",
        "\n",
        "print(\"\\n\\n########################################################################################################\\n\")\n",
        "print(\"default hyperparameters:\")\n",
        "sokoban = SokobanEpsiode(is_a2c_small=True)\n",
        "sokoban.run()\n",
        "\n",
        "# print(\"\\n\\n########################################################################################################\\n\")\n",
        "# print(\"critic_lrs:\")\n",
        "# for critic_lr in critic_lrs:\n",
        "#     print(f\"\\n**HYPERPARAMETER**: critic_lr={critic_lr}\")\n",
        "#     sokoban = SokobanEpsiode(critic_lr=critic_lr)\n",
        "#     sokoban.run()\n",
        "\n",
        "# print(\"\\n\\n########################################################################################################\\n\")\n",
        "# print(\"actor_lrs:\")\n",
        "# for actor_lr in actor_lrs:\n",
        "#     print(f\"\\n**HYPERPARAMETER**: actor_lr={actor_lr}\")\n",
        "#     sokoban = SokobanEpsiode(actor_lr=actor_lr)\n",
        "#     sokoban.run()\n",
        "\n",
        "print(\"\\n\\n########################################################################################################\\n\")\n",
        "print(\"gammas:\")\n",
        "for gamma in gammas:\n",
        "    print(f\"\\n**HYPERPARAMETER**: gamma={gamma}\")\n",
        "    sokoban = SokobanEpsiode(gamma=gamma, is_a2c_small=True)\n",
        "    sokoban.run()\n",
        "\n",
        "print(\"\\n\\n########################################################################################################\\n\")\n",
        "print(\"epsilons:\")\n",
        "for epsilon in epsilons:\n",
        "    print(f\"\\n**HYPERPARAMETER**: epsilon={epsilon}\")\n",
        "    sokoban = SokobanEpsiode(epsilon=epsilon, is_a2c_small=True)\n",
        "    sokoban.run()\n",
        "\n",
        "print(\"\\n\\n########################################################################################################\\n\")\n",
        "print(\"epsilon_mins:\")\n",
        "for epsilon_min in epsilon_mins:\n",
        "    print(f\"\\n**HYPERPARAMETER**: epsilon_min={epsilon_min}\")\n",
        "    sokoban = SokobanEpsiode(epsilon_min=epsilon_min, is_a2c_small=True)\n",
        "    sokoban.run()\n",
        "\n",
        "print(\"\\n\\n########################################################################################################\\n\")\n",
        "print(\"epsilon_decays:\")\n",
        "for epsilon_decay in epsilon_decays:\n",
        "    print(f\"\\n**HYPERPARAMETER**: epsilon_decay={epsilon_decay}\")\n",
        "    sokoban = SokobanEpsiode(epsilon_decay=epsilon_decay, is_a2c_small=True)\n",
        "    sokoban.run()\n",
        "\n",
        "\n",
        "# sokoban = SokobanEpsiode()\n",
        "# sokoban.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 4]\n",
            "Box mapping: {(4, 2): (3, 4)}\n",
            "critic model:\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_204 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " conv2d_205 (Conv2D)         (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_102 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_206 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_207 (Conv2D)         (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_103 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_208 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_209 (Conv2D)         (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_104 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_34 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,869\n",
            "Trainable params: 813,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "#########################################################\n",
            "actor model:\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_210 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " conv2d_211 (Conv2D)         (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_105 (MaxPooli  (None, 32, 32, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_212 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_213 (Conv2D)         (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_106 (MaxPooli  (None, 16, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_214 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_215 (Conv2D)         (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_107 (MaxPooli  (None, 8, 8, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_35 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,869\n",
            "Trainable params: 813,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Episode 0, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 1, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 2, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 3, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 4, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 5, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 6, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 7, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 8, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 9, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 10, Steps: 500, Reward:-51.00000000000045\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 11, Steps: 500, Reward:-51.00000000000045\n",
            "Episode 12, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 13, Steps: 500, Reward:-51.000000000000455\n",
            "Episode 14, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 15, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 16, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 17, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 18, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 19, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 20, Steps: 500, Reward:-51.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 21, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 22, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 23, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 24, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 25, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 26, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 27, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 28, Steps: 500, Reward:-51.00000000000046\n",
            "Episode 29, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 30, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 31, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 32, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 33, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 34, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 35, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 36, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 37, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 38, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 39, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 40, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 41, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 42, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 43, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 44, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 45, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 46, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 47, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 48, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 49, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 50, Steps: 500, Reward:-51.000000000000476\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -51.0\n",
            "Best reward so far: -51.0\n",
            "Episode 51, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 52, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 53, Steps: 500, Reward:-51.000000000000476\n",
            "Episode 54, Steps: 376, Reward:-24.60000000000025\n",
            "Episode 55, Steps: 500, Reward:-53.00000000000046\n",
            "Episode 56, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 57, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 58, Steps: 500, Reward:-53.000000000000476\n",
            "Episode 59, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 60, Steps: 500, Reward:-50.00000000000044\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -50.5672131147541\n",
            "Best reward so far: -24.6\n",
            "Episode 61, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 62, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 63, Steps: 500, Reward:-50.00000000000044\n",
            "Episode 64, Steps: 369, Reward:-23.90000000000022\n",
            "Episode 65, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 66, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 67, Steps: 370, Reward:-24.00000000000022\n",
            "Episode 68, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 69, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 70, Steps: 371, Reward:-24.10000000000028\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.92676056338028\n",
            "Best reward so far: -23.9\n",
            "Episode 71, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 72, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 73, Steps: 371, Reward:-24.10000000000028\n",
            "Episode 74, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 75, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 76, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 77, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 78, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 79, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 80, Steps: 500, Reward:-50.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.22345679012346\n",
            "Best reward so far: -23.9\n",
            "Episode 81, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 82, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 83, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 84, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 85, Steps: 500, Reward:-50.00000000000046\n",
            "Episode 86, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 87, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 88, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 89, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 90, Steps: 500, Reward:-49.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Average reward so far: -47.47362637362638\n",
            "Best reward so far: -23.9\n",
            "Episode 91, Steps: 500, Reward:-49.00000000000046\n",
            "Episode 92, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 93, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 94, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 95, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 96, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 97, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 98, Steps: 500, Reward:-48.00000000000046\n",
            "Episode 99, Steps: 500, Reward:-50.00000000000046\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "sokoban = SokobanEpsiode(actor_lr=0.1, save_every=10, episodes=100, save_rewards=True)\n",
        "sokoban.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b_m9NGvEdI7T",
        "outputId": "8415297c-ccf2-4601-8ca6-2a8d0fc4453a"
      },
      "outputs": [],
      "source": [
        "run_video(trained_sokoban=sokoban, MAX_STEPS_IN_EPISODE=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLSXZFn8c3A0"
      },
      "outputs": [],
      "source": [
        "sokoban = SokobanStep()\n",
        "sokoban.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe-WWYbedbAj"
      },
      "outputs": [],
      "source": [
        "run_video(trained_sokoban=sokoban, MAX_STEPS_IN_EPISODE=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__K3hWM6VqtR"
      },
      "source": [
        "# Feeling the Env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDaTYUJ4iufr"
      },
      "source": [
        "### EX1 - FIX SCENARIO -  PUSH & PULL - ONE BOX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqa7N7WS9M8G"
      },
      "outputs": [],
      "source": [
        "#=============== DO NOT DELETE ===============\n",
        "np.random.seed(2)\n",
        "sok = PushAndPullSokobanEnv(dim_room=(7, 7),num_boxes=1)\n",
        "# state = sok.reset()\n",
        "np.random.seed(2)\n",
        "# state\n",
        "# pdb.set_trace()\n",
        "# ============================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "0hRklyCV55JZ",
        "outputId": "b826eb1d-f769-458f-d0b2-a7420f4f5b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[2 5]\n",
            "Box mapping: {(4, 2): (3, 4)}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#=============== DO NOT DELETE ===============\n",
        "# random.seed(2)\n",
        "sok = PushAndPullSokobanEnv(dim_room=(7, 7),num_boxes=1)\n",
        "random.seed(2)\n",
        "state = sok.reset()\n",
        "# random.seed(2)\n",
        "\n",
        "# np.random.seed(2)\n",
        "# state\n",
        "# pdb.set_trace()\n",
        "# ============================================\n",
        "old_box_location = find_box_location(sok)\n",
        "observation, reward, done, _ = sok.step(0)\n",
        "new_box_location = find_box_location(sok)\n",
        "target_location = list(sok.box_mapping.keys())[0]\n",
        "# reward = reward_shaping(reward, old_box_location, new_box_location, target_location)\n",
        "\n",
        "creen = sok.render(mode='rgb_array')\n",
        "plt.imshow(sok.render('rgb_array'))\n",
        "print_env_det(sok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 1, 1, 1, 1, 0],\n",
              "       [0, 1, 1, 1, 1, 1, 0],\n",
              "       [0, 1, 1, 1, 1, 1, 0],\n",
              "       [0, 1, 3, 5, 1, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# random.seed(2)\n",
        "# state = sok.reset()\n",
        "sok.step(3)\n",
        "sok.room_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjJ5QFXxnXjy",
        "outputId": "3731e188-d45d-4156-87e7-4efb99a0a804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [160, 212,  56],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [142, 121,  56],\n",
              "        [243, 248, 238],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [243, 248, 238],\n",
              "        [254, 126, 125],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [243, 248, 238],\n",
              "        [243, 248, 238],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]]], dtype=uint8)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sok.render(mode='tiny_rgb_array').shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IXftqpcxw4w"
      },
      "source": [
        "### EX1 - Video test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "MF9LTmkst9wL",
        "outputId": "898d5ab4-0687-41ea-997a-6b52851734e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/imageio/plugins/ffmpeg.py:727: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  self._proc.stdin.write(im.tostring())\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAIMFtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1NSByMjkxNyAwYTg0ZDk4IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOCAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yNS4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAMGWWIhABn+fj9HG4CKW2DktdjB/ktMw2Q1cN3MTZ6GsOboRuaMfkRrquXlZWUXdxTYYh22WGLZ5lTEU0WcxG/97fUkYeVE7fVsbEqMxum2nPNpGXZwDIfimYqFk8Lzf//goqJMlFViVMJkvYRc6njLpIQVLjAWTCAL0gyuHcmlXZtHKneguxwUp2D33Aw64ayG9LeOASBzn+x4svmb0/dNG/H3mrw0m/OFcTetnbig7gTSk0JYGWGDx5X+uPzTk/oo5fYRsTTFZLDvfPspwMSAsD6YZdJuV4O1R716Ws0yczULtwbezRj8JCF1VY5qRXIosBRL/RVJg08rxxcthxYBgRGdTKjQNXPRSCvr1stDn/7dleuZNhkZORGEDWc3WyhxU/ZX+Q3yOzYXl/LpKBcs2qa0VjFMa4B7kwBub+3CT0R58blBvDKUqUiipzkxivOxq9fYUEACn6vwTLUkZDLa/BVPJhfLaTbnrCKQHQc/hmFYu5LS4QTu+KeSDEQd4VmIrYSC7uZfimKB33PtJk5oTL0N76HsxDfUQwsQHZEFERPF0KPFK/0moV5fnv0zN3BK8mXLrYDOeCjrOy/ERn0cZjRe1OwdwSREICKsUJn2iP34lprcAW4+Q49oos/5pKb8/G6pABswlxx/hPH94iS7Z+lf3eBm2hyoeCnbw4S/9DPaCExqDZ46yLcqdzRovuOUqeaGoRa8ZzhwgqTO1/YRVnOAJBBu1T8xUygm/zawz5prIabew8hGDnKFmpAAtxrT9X9LhD4kpGDe7iAV8WCQJV9zrxaaty0o+klI7dQKUjQ5ajcsL2betM6PfHqgqMTzjglDDsKXFe0pEFRiWUooy41+ufgmWY5/MJwRc0OiizUzRf3xqVNpigo66JqIGI/HWu/Wymp7EUWsb8n5ZT8GMh+zgEBUIgP/xAfF149aMsbevpn92Oe3JeThLzWH6qnxqZ3e6w9u1jBz7g3XeUdWZY39/Iq8LDWRnxOpO/ZvIJigIHZ/1bsDvR/Tnr34dklSK9bCw4FEKnAWY6GQlOLJlIdDfBPRtt98ka5g1DAUKZSODK78vBZt4vtzepfFTLTL1UHT3gaJa1ThfM2JAjU5F8aaWbjJUlSZkFvZ4xTEaRoWf2J102v2/ASPQx9Wk3mpeumfGwRAdW2e6LKyVtX1qJSvshDMCRmhYOimI+zTr7wa4D57iNWgQD6BhOhogCnVOtgKE+f1HpYI/T0ay3aOSngpjRgJJA78/bZtBKkzIGvW4vbT8tNPSDd6bbVw8SN+LjaXmX4gxW6SasMnWzVoAwxrkUBtF4WpJfhVOhWMOAx6hgEF2ClQJ4bcoWXJcO1GFCg8d0rh8BZc9s4BloMQZ4xsQ615Sz/vHdMfJpLaAUxlvvS0Yc/E79q5dArKb6ppb+EN+dDETqwhDO+pCj197GGRyLLIWirahg1IQRE4CcAfS7HWOJnrX1hw7N131NEhAvE+0XrIwHz6lz4JZb086K9SQo1vAfADblj4nnFUn2BY2tSNlmQX5k5pPxgyCLes2CBsLXrbWYpEF1HxW1RZidpNOQmJFaXgggL7458CTF0fxvPzqM2Yr3IZaexomfZGsbCb/s8JEonvv5OssQ06U6CY3wrjwrTRxAVrYMxUI+HKyhHjJ+ROzYKMAiQC7FgbbT42g2MjJTiIIQXTjf7HQFhSERBXL8dRK0rgqOHAioMZxAiw23NWmrv7sFDzlPVwDpkVMwCSygCXZuWCABlk7hvIKfI0h48+JMGK2iORzROu9n5I5QuUgepdOs1IAwL2EyvnAY5nMV24XZlqW2f6iatsoKhjNGt1PvC18MlN8l+9ihIOW/8MUQ838Mpv7jBOi2fCwG9Nw/f6wb6m5BlSWnAwCUx1RrPfNOBKqJCxspzEVKSTqA/2MAsX93uf7kbBoFkWH+YyGgLTfQPMcC8iZnyHFWvRYOzXYlluvBup1eVznCq1WRCMmGJABIQtCYbdyPwdy2AC6FrgNBOVaXUCqbDsV1I58Nq9EfzR+Uh+9pBG5iryJg2AcIpU03qeVv76sb7UXU8csRMGtaEuEQ6XohHtpKaPlwGCWY3d4aPZf3ZVF1BMgP4yoWBV7j3HYvpU9P2W4DYLxwpcQ5fXbQQORyI+chZE4IFMY/FWt444OQT1a0Pg55vUIs5bn/wlHXzCd0n3+WbuJ4OGkOSkjOyHrs/C1ZKnk90ZUM0pcNS5UKAk0OuS41Qwc7e8greCOkD2fU1A4zGklpl6pycyww1Xskp34pjRgNAAkQwpRV9SMAwXnrHxA/23SCJRdQX14J3KYurJcAJrmoxX6DWQbppPZQet4CDVXxu0xkUbeqqZiBgid91WokQNx5jnELRJ4om0ZhuMB6wr1fiD6Uyr6w6GzysP4pCpqXUWn/8LX73mXcfjIQCUljik3VZfhBDBJBUqDuQy8YdKlkfFUoznGyAVTLPxGlb82AngcTV0LHe7JpJoC/buVJzIiJSc2TGnvXpSqOcgk/PxanLpRzg9r8FwgEYBgvsauOgVHdNiofekNQQ9DoKcqqHLI+UQRlIOIJepaO0VgvvYMJd93jIoHqwlsbPI+ig1j44S4SDnV+EyFcXXu/veD3N/pxnA6qdLO9ROA7HZFdx+Zap7z85rxLPRlyyHR0n3pH7TL4UYL3liSdLIrWnGGSBnWyfBmfcBms5+POd4B3Ck/0fWNsGGwQPZOFGwC9xFHB3ln6UcbFG+lHSpRKzw38EOs8Ww/m/HDssK8eMRVGM8K3jfb9XjQy1uFJqy/gv1vFwPmxcuNJVateiSphiMZ6fGvQg2DErc9IGtRAesdBzpPk51y0+AP6+6ahUOTTf+IOTGbfaEFUkH9TwjGRoTD9i1203I/juosVSLcoJELmOzZo+D+JQ2AA3jfoQ/r4BgizwakqApz7jHRed1gQNHd+lmgtJ2k+GAzRHo7T5TwhYjyFidrh6KFqwlSOxDFY0o8rVEhJS++ZWcBgqVsI07v+o/hQbvSBGnJmZDrZ5NeDJA+Ea7CJIu18z5dyNmnKvv7RGiGwYAagY7rihmvn6Qy8AzB+UN2gCZHVgUqfBLkBoExt8elcyNhnrsCu3rLEgRg1ojHsahCalMz6+enG9Hm7aHvwU+9Ig6Y3VEjzQkGq4pXLXpp1n2zqrmE3rGGnh0BG8NDXUFLgF839lKPWHXyhXbPn18ojXrYfCvnih3/t1ZCzjpmp2qj23Dxp1/B4w01RC5qT+14QFNgCbTbyT4YeuYgRWOsdxQynCkuYqlGgX2l2R9askXrjs10B43pzTJtC1iBx/KGXC+fEsKZTdXazasJRki70WloZs6S6RePlswg056yzqReBAT+YRP/ssgjsqK5o0yuJERpeuRv9NcTYW60hC7dvi0pgXfgWOLOsePG85XS9MOhLQHR3lRg/UDoUErqnUP5FmLF3j9u1aK8vjc1/u4IGJmNr/6K9ED2CTFHWmk8/KbqIIWHU1Je50hl0Lly+dwNFvdkwPswhZVg4NKQqFqg8/VCKmTQc8O1teF5pkgtzT16PA7/YHQkeiMkqz2BaDFjijxTdA7HalgUumhosLySSRoOUvSwYd1kp7wY2evl/+z1A/VML+4Oy2EsVnmmpXDL8WidtmnPyj4oQp1cMxiRT/Mp39xSmofmppoCZ/a0ayptrfKnJNl8emcJkRjloKVDBrWJhttLjtVgnIE6QmpcI5FBPpnxomPy1qrhtIwwfdbx0KnH4YiNjUT6Hiujv19H1jYZDhZ6j8Cy0LZBqz2sC3uBaP8EcmqwqSg2PZmULjVsIJuPhM1rJBlpK1veuqJ/QFa+e2XjnCqkXwjrP5AOckibINiDnKqOwvkKH6ZAeXp0ZbRSwES/fzojyhK5tiAXuYfKdITYRRZjxt0HFrXX7QHdi+qhnLPZs8XH30M+DOZ6JGKO0Tqb/5W+7hRhggn7HJN1gv78kIWQsMCnrEzggzFS6lwR14Rh/DDsX50GtbZtAd2L7gvR0Hxz6RYsWfwZzPRR13uk2ywJu2MkO2weLTrijhPCVfDF+Ws4VYx1O1SXWYVB5VMAP4Ydi/gZtrcFoDuxffrB7Q+OhOGFk3+DOZ6K6wsyUtkKlJIt6AmLank7r0YhapN9khBbPJFeEAAACWQZohbEX/aeDnh0AMj7FHt4h40q/pqnSNFljgzyHEU+Rh85CtdIaQFOQ/DFE+3vnx6GXGWtzbCkmcbasimghWV9jqw5DhpU/toWqr3H9uuLDi672ZrDARA0/UW3phJLwDxu57vgDCZt5OD73quiGar/0SvEvrwCvZnlt+WDb+d44NtiQMkila+WIdllljc7ZruvWcte2AAAAALUGaQjwhkymEX+VIdtC1bHXwVGngjyMNtbS92xKPOAHHOfjC4i9Cg7j6cYPVYQAAAA9BmmZJ4Q8mUwIv/+RAIqAAAAAPQZ6ERRE8R7Rx2sUA4OfRAAAADQGeo3RGf7WyEfEkVoEAAAANAZ6lakZ/vMybywe2gQAAAM5BmqhJqEFomUwU8X/k5Y+Th3Ve2wftgwU/BcQbITfioCYp4bydkTf6FDcqgNnQADs971P2LpDffdAah8/VT80CIH8zqsyv5fr0jn9Ebmd80GvEvmibLAH/uEBzjov36OSGu/LHoRCnggS+x6r/4YMSg9ra+Zoo7S0CvxIK4AiSX94he+KqdsAlWFH1kL1LAn8NsvY8kK9gccp6NPUj36Xb7GFALbtoEcNyBiuelwbfra21C+NKS8ScNaVf/b004E5otITh0cJNaSNifziJ+QAAAA8BnsdqRn/AGSSJMSqTF5gAAABOQZrKSeEKUmUwUsX/+mlkq4o/jdoA1+sNhXqcg6YCQj4nen4sxBlB6/cq6FNomZlU68RXBVyzannnaIZjdDlVlDtEvIg+qQz4XfY663pAAAAADQGe6WpGf7YEX5Kmr7EAAAAQQZrsSeEOiZTBRMX/5EAioAAAABMBnwtqRn95lwb252HaNmAIbX/TAAAAD0GbEEnhDyZTAi//5EAioQAAAGBBny5FETxHTokjLzySFBEveLtkEvMUJQ8RGJ8DxarJyYif/4lld/bwGPn/o/tuqA5UJl7fZRCf2HZbs+bx6GESoJrvKFINCKnAGnvabXhGafIgZz06rhoMGvZiLQfYe+kAAAAOAZ9NdEZ/Wl9gWQ8QuoEAAAANAZ9PakZ/WYzARMfAkAAAAB1Bm1JJqEFomUwU8X/k4PAuNPgAHCjt/KIB8Wv6+AAAAAoBn3FqRn982QotAAAAG0GbdknhClJlMCL/5OaO4Rlt2zYXjBaxY8mA+AAAABJBn5RFNExHev5kTFk2qO6pvhgAAAAMAZ+zdEZ/fyRhMHbZAAAADwGftWpGf38dBQA/Kzd94AAAADlBm7pJqEFomUwIv+SjDUjLIPaNCCxCJIZFdu6IA+Uon6hIb5pzj3T0NxAxhPiHHqQZv3kDUvZNEFEAAAAWQZ/YRREsR3J+l0QNALJO4JKo3gHIUQAAAA0Bn/d0Rn9V6z2opg71AAAADQGf+WpGf3TqyXGLsD0AAAAtQZv7SahBbJlMCL/uTM/Z54O12pQqBfjW7jJQL2ahG5hcC413JXoVilKByK50AAAAPkGaH0nhClJlMCL/6YJn949Nt9FgHDmjFRagsvbYubz74CQbsRh3GGZ9iyJJU7E0nYRwY4gAw3J87YBcYcYVAAAAI0GePUU0TEeUW4jFDAOAEDVv8R8fCCiUwY69iKIHP+g7oTLZAAAAEgGeXHRGf5wfB4wAVE0JYv/xoAAAABYBnl5qRn9v2XTSku6gBB3GZNHAIHzpAAAAFEGaQ0moQWiZTAi/53ACjl/3IR8RAAAADkGeYUURLEd7tyd8ejSMAAAACQGegHRGf5GsPQAAAAoBnoJqRn9v2Y71AAAAJ0Gah0moQWyZTAi/53CWhmRUwAyi+vqcl9YSz6jwVJR9Tl79AnIxIQAAABNBnqVFFSxHc+wO2QAPqPb4dVFBAAAADAGexHRGf3Lxw5aEoQAAAAoBnsZqRn9ribJhAAAAD0Gay0moQWyZTAi/5EAioAAAAA5BnulFFSxHe7bUPrNd0AAAAAgBnwh0Rn8hoQAAAAgBnwpqRn8hoAAAABVBmw9JqEFsmUwIv+SCkx+1xHe82IAAAAAOQZ8tRRUsR3u20mOIY8sAAAAKAZ9MdEZ/a4Y7UQAAAAoBn05qRn9v13XTAAAAD0GbU0moQWyZTAi/5EAioAAAAA1Bn3FFFSxHc/cl74kjAAAACwGfkHRGf2uHBUoLAAAACwGfkmpGf2uK5bQWAAAAGUGbl0moQWyZTAi/5KUloAdCxjm4j1TEu4AAAAAMQZ+1RRUsR3Pz4/MtAAAAEgGf1HRGf2+S2mYAP8ifIF41gwAAAAgBn9ZqRn8hoQAAABZBm9lJqEFsmUwUTF/kowzmH1yNJOKBAAAADgGf+GpGf4T3II2dXgzgAAAAx0Gb+0nhClJlMFLF/+SqNe1KwzuVPaEA+RIKGqSZHTniTNqRRknZBeXgD0FuigVuW/ew6PRELbGVp9EFdPzQC5dkD+4M2JFehh1BOVi3lYQmRmKoPtW89aVj2afHovBf90nBATMkDi6Whq0cxVpqlNdeBzQbHy/vrgq7ZDac5RxhQkZC5uwn8NsvZHq/T5HXkPY4/TQFKWMmJ5+ZfaYbkDFR17l5etnTJiLv6XiTgJPXjKCFZCSB7cgWBvpJLJmhWYSMhjWXUoEAAAANAZ4aakZ/dkErgpdzWAAAAC9Bmh9J4Q6JlMCL/+SOvN/WkAq3MFfaNTKRSaIxquUg7gjZOHAm88Gr3x97Qi9agQAAAA1Bnj1FFTxHUBBmae7VAAAADwGeXHRGf1Vz4s+Z/VWAzAAAAIEBnl5qRn9ySgWWNkBkE1DuGXPy8sf0vl+ctVGOIau9FWPJSeuhg9WGBwf8BJzdEoH+Sk06qHZh1B+u+vk24GkNDbfN9UhaxH8prlvirEaPPs5+UwPaMmfqEnGuOSzibjRFRNhf/MrguvLCdB8AhQe65VrfMsGyNB6KoeXNL6CtHXAAAAAcQZpDSahBaJlMCL/kpSWgCaRqpDSMSU0oRlZSQQAAAA5BnmFFESxHe8C+T9L6EAAAAAkBnoB0Rn8+3O8AAAAoAZ6CakZ/Vay1El2L/LgAVWl+E98iSYeE4MSsOdjkD23Qd56m4z0xXgAAAC1BmoVJqEFsmUwUTF/ktkhOQNDOgB4yYlMnnoIiAuMd6nkwAMKY3OCWvz3YgDkAAAAOAZ6kakZ/hQDsE4QV3c0AAAAVQZqnSeEKUmUwUsX/5ODwLcmULcPhAAAADQGexmpGf3i/0KfxWJcAAAAfQZrISeEOiZTAi//k9yaseknV3fKl9PBxFlpVgfY5sAAAAKJBmuxJ4Q8mUwIv/+Sq6TlGPgrz2aFkJODBBInwDoOBRWiV6jkFkE2ORz45I3uzxWcVag4eLtSNnDAfBG5T8DFN6GkgjHn4ZKZt+VxgrS/+v9SAB5GSNw2KQErSbVVsIlQudIEQJaUg4U/tPMOpgGwlrRzSVk2SwgfyUnXmF+l35zl7kPZUf/VclCPQlYXypo9YneV6hFeE7J6KXSYV8+nysoAAAACPQZ8KRRE8R2lC7JYxo0Hh9lKmv/4XdXssxyjIntuwne7jLxUPivPorW8CNHRy2ob/Iddd9W/ThKd8dV4EaTsPlWTcF4JoLyGNknsm5D2VXB+b3qaEMp1aFlpq6+VW1IRFXmkCPEhZ0wcNKSum1qwBHNzYNCOiygMIbD8z8anJbNppUz13LNPUVwUvXZndzpcAAAAPAZ8pdEZ/ciOJBg1kh4otAAAAEQGfK2pGf1qFIgT1J4C1LdXAAAAAD0GbL0moQWiZTAi/5EAioQAAABNBn01FESxXVQ4WbKhGXOK3o5zBAAAAHQGfbmpGf0BgzhVxddgAFJf0godLDUAgdloary6xAAAAmEGbckmoQWyZTAi/5ECLGEdZReKxNUSmHCDBAqPYB0HAo71My8wK9CeDYzWKrxuHk7pxpVsuyUTkqiumx8/TLv/n6+3EIYKt7k0Hj+j62r6tp/xAiaTlViZpnSvUMzGhCujSCTVwrYQakItBENgpo44TeyVk4EcSTCFSxUCoLQefG9qpL+Zl4ebI0XuWfdb5ibTxGFt9ve7AAAAAEkGfkEUVLFd+nXV1iY6pWZBYUAAAAA0Bn7FqRn8/wHHaKlnxAAAAH0GbtEmoQWyZTBRMT4cBwTMKFHCFALS0SOJHkdJ5sIAAAAAQAZ/TakZ/WyQ3OQx9msN0YAAAAA9Bm9dJ4QpSZTAif4cAfkEAAAAiQZ/1RTRMV1FCbtYs4ciNwKgBDyzvfoV2NhyDIZW//wxK4AAAAB4BnhZqRn9AYM35A22wACnUqMaL549zFR40tztx52EAAAAaQZobSahBaJlMCJ+Hqk14+EFzCLqqssIJxLEAAAAVQZ45RREsR04kXs4gSsO4poIB894EAAAAEgGeWHRGf0BJE4ay3yABVJsWWwAAABQBnlpqRn9PV0YvNg6dNACJx97CQAAAALBBml5JqEFsmUwJ/wADDgmFjCggSiMZG0zFLl6bYgxn2z3N9GMBRIM1kt11j3Gng9b0Dim5rX4cWJ1oWi5ZJIboHq8DWxwoMWM0/9UBzsnliQrndJOgNAbCli6AyxLNlzQeK21S1tYY6CeelFbPcJIK56uhX29n5iJPBg55pplht8uZsnKyhhK4fR2XJDe/JLfTVyo1H6Ey2EaoaRGH+MSOUSAc8/UC4gM8EMgnrzZ7QQAAABZBnnxFFSxXURQ3PnN2YwAKSmYwekF7AAAAFQGenWpGfz+7xQzE4BK2/H8JzT7l8AAAABtBmp9JqEFsmUwJ/wADAZLTa57gzAYoQp5ZqGAAAAAuQZqjSeEKUmUwJ/8AAwZG6IB9B8CMYg1RTffgljTcT/4Ukf3caLcUuV6DjHa6uQAAABRBnsFFNExHTkwd0025+XlnjpYtjgAAAA8BnuB0Rn8+2jzqcnWIu4EAAAANAZ7iakZ/P7vi8Zn0nQAAALtBmudJqEFomUwJfwAJPsoReJPqlUgPeOy09XR2rRPd3yTr5fR6Lz/+HZzOD/UYEi557pSHzV1C8KLwNL5pL+ExIEZq1AHtRbJLfNPL0Muie0JMNe/qJDW4KSLm9JSG3E79I7vuCtNJBJfPJSFoGlTMRIpcu+PJPevj45Q3xJZWIZqtdyy/26qWgn4iBNzzIVYeVufFXEP344iWaVgS7Xce2sEf0tbcB8HHoBFWpSbT1oSbznZ6Uhau69exAAAAEEGfBUURLEdOIzMqQwHjQGEAAAAOAZ8kdEZ/PtU6qB252sEAAAAKAZ8makZ/P7veNQAAAH1BmyhJqEFsmUwJfwAKEKuCnznweNeFov7SQw//6YdYUtCZqGpGaYiCE/3CJIv99JTG6/4vuANgc0DIrMn+NxkNQnnaVzQWQC57wWpEn4hCAbdqGQxedKzSZ9ywjq85UVoMqDwur7nFpfPLiS6fzdebCsYclrIt1RyYaKdBwAAAABZBm0pJ4QpSZTBRUsv/AAtAvRAHA+lgAAAAEgGfaWpGf1eVoLYwI2vcoyvTowAAADhBm21J4Q6JlMC/AIbsXMAYzoluv5vftP2tsCKGji/RkppjXYyTFyeJ4D5xwJQUH7pk14DcvI84QAAAABFBn4tFFTxXUYJTiRBAP0MtoAAAAAwBn6xqRn9af0lA2H0AAAAhQZuuSahBaJlMC/8AC0u0lROHQiZat7MRS+WzbFgrd6wRAAAAE0Gb0knhClJlMCv/AD92b2k/8HEAAAAQQZ/wRTRMR1JPzeKScBCoNwAAAA4Bng90Rn8+102RKll7wAAAAA0BnhFqRn8/umITqE+BAAAA1UGaFkmoQWiZTAjPA++wv2L4XuI1zVAY/fehJy1UY4hq70VY8lJ66GD1YYHB/wEnN0Sgf5KTTqodmHUH676+TbgaQ0Nt831SFrEfymuW+KsRo8+zn5TA9oyZ+oSca45LOJuNEVE2F/8yuC68sJ0HwCFB7rlWt8ywbI0Hoqh5c0voKyrTFpNyvA54wq5yF+1m6ZQ/uWV38IRfAGvGbnHcG/HL6xaFVfIwg2Nb2uUHrcEi2gW7HSJbcVZSceEm6QVvmL978rAEFen0aEzi+scwfg8OICIufgAAABJBnjRFESxHe8OhNzRC0oEz1AgAAAANAZ5TdEZ/PtiDOIHCwQAAABEBnlVqRn8/s4odxPlyyWsjYAAACGxtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAufAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAHlnRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAufAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAcAAAAHAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAALnwAAAgAAAEAAAAABw5tZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAAHcAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAa5bWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAGeXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAcABwAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwFkAAr/4QAXZ2QACqzZRz6EAAADAAQAAAMAUDxIllgBAAVo6+csiwAAABhzdHRzAAAAAAAAAAEAAAB3AAAEAAAAABRzdHNzAAAAAAAAAAEAAAABAAADkGN0dHMAAAAAAAAAcAAAAAMAAAgAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAMAAAAAAEAAAQAAAAAAQAADAAAAAABAAAEAAAAAAEAAAwAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAAAwAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAACAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAAAwAAAAAAQAABAAAAAABAAAMAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAAAwAAAAAAQAABAAAAAABAAAMAAAAAAEAAAQAAAAAAQAACAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABAAAAAAAgAABAAAAAABAAAQAAAAAAIAAAQAAAAAAQAADAAAAAABAAAEAAAAAAEAABAAAAAAAgAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABAAAAAAAgAABAAAAAABAAAIAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAIAAAAAAEAAAwAAAAAAQAABAAAAAABAAAQAAAAAAIAAAQAAAAAAQAACAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAB3AAAAAQAAAfBzdHN6AAAAAAAAAAAAAAB3AAAOzwAAAJoAAAAxAAAAEwAAABMAAAARAAAAEQAAANIAAAATAAAAUgAAABEAAAAUAAAAFwAAABMAAABkAAAAEgAAABEAAAAhAAAADgAAAB8AAAAWAAAAEAAAABMAAAA9AAAAGgAAABEAAAARAAAAMQAAAEIAAAAnAAAAFgAAABoAAAAYAAAAEgAAAA0AAAAOAAAAKwAAABcAAAAQAAAADgAAABMAAAASAAAADAAAAAwAAAAZAAAAEgAAAA4AAAAOAAAAEwAAABEAAAAPAAAADwAAAB0AAAAQAAAAFgAAAAwAAAAaAAAAEgAAAMsAAAARAAAAMwAAABEAAAATAAAAhQAAACAAAAASAAAADQAAACwAAAAxAAAAEgAAABkAAAARAAAAIwAAAKYAAACTAAAAEwAAABUAAAATAAAAFwAAACEAAACcAAAAFgAAABEAAAAjAAAAFAAAABMAAAAmAAAAIgAAAB4AAAAZAAAAFgAAABgAAAC0AAAAGgAAABkAAAAfAAAAMgAAABgAAAATAAAAEQAAAL8AAAAUAAAAEgAAAA4AAACBAAAAGgAAABYAAAA8AAAAFQAAABAAAAAlAAAAFwAAABQAAAASAAAAEQAAANkAAAAWAAAAEQAAABUAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjkuMTAw\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = sok\n",
        "start_time = time.time()\n",
        "done = False\n",
        "iter = 0\n",
        "video_filename = 'imageio.mp4'\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "  while (iter < 10) or not done:\n",
        "    time_passed = int(time.time() - start_time)\n",
        "    if done or time_passed > 3:\n",
        "      break\n",
        "    iter +=1\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    video.append_data(env.render(mode='rgb_array'))\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOt9e38LiUX_"
      },
      "source": [
        "## EX2 - PUSH & PULL - ONE BOX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuO5Vz6X9KFP"
      },
      "outputs": [],
      "source": [
        "#=============== DO NOT DELETE ===============\n",
        "sok_2 = PushAndPullSokobanEnv(dim_room=(7, 7),num_boxes=1)\n",
        "# ============================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "YzYaMz7drkE3",
        "outputId": "57f36403-3547-4b15-f450-ee8d7c31cb8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[3 3]\n",
            "Box mapping: {(3, 5): (3, 4)}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "screen = sok_2.render(mode='rgb_array')\n",
        "plt.imshow(sok_2.render('rgb_array'))\n",
        "# observation, reward, done, _ = sok_2.step(1)\n",
        "print_env_det(sok_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-bPP5tn0IvJ"
      },
      "source": [
        "### EX2 - Video test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "A_gYNbckuIu3",
        "outputId": "6d781aa5-9b44-4032-c9ad-82036e6dcc81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = sok_2\n",
        "start_time = time.time()\n",
        "done = False\n",
        "iter = 0\n",
        "video_filename = 'imageio.mp4'\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "  while (iter < 10) or not done:\n",
        "    time_passed = int(time.time() - start_time)\n",
        "    if done or time_passed > 3:\n",
        "      break\n",
        "    iter +=1\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    video.append_data(env.render(mode='rgb_array'))\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-gRY9mtZ-6J"
      },
      "source": [
        "## EX3 - PUSH & PULL - TWO BOXES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFbVwDqf9C62"
      },
      "outputs": [],
      "source": [
        "#=============== DO NOT DELETE ===============\n",
        "sok_3 = PushAndPullSokobanEnv(dim_room=(7, 7),num_boxes=2)\n",
        "# ============================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "eb1TWQqCaCf_",
        "outputId": "895ee209-f343-4fb2-9e28-52e4d09d7c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 255.0, (112, 112, 3), float32)\n",
            "Action space: Discrete(13)\n",
            "Player position:[1 5]\n",
            "Box mapping: {(1, 2): (1, 4), (2, 3): (2, 4)}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "screen = sok_3.render(mode='rgb_array')\n",
        "plt.imshow(sok_3.render('rgb_array'))\n",
        "print_env_det(sok_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIk_Xm1i0TzJ"
      },
      "source": [
        "### EX3 - Video test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "uXs6GziOuWD9",
        "outputId": "f4e49dd7-238d-45c4-a8b7-a43892d3515d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = sok_3\n",
        "start_time = time.time()\n",
        "done = False\n",
        "iter = 0\n",
        "video_filename = 'imageio.mp4'\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "  while (iter < 10) or not done:\n",
        "    time_passed = int(time.time() - start_time)\n",
        "    if done or time_passed > 3:\n",
        "      break\n",
        "    iter +=1\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    video.append_data(env.render(mode='rgb_array'))\n",
        "embed_mp4(video_filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "J7bJeRHbwMIj",
        "OYGqP1yr7iJA",
        "__K3hWM6VqtR"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "RL_hw",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d51ee4d70b2c23766beb992ad0eed997083b0a2674613baf74baffe731117cf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
